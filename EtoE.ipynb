{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EtoE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "7TOF0lrPSieV",
        "dzsFqWcY8mgI",
        "NbI4LHIhH0Ai",
        "ODTxwVyq692H",
        "I7WKQkI0AQZo",
        "Q3kR3cfwC_Zx"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richard-cartwright/personal/blob/master/EtoE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "XmQwme3DMIBl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ]
    },
    {
      "metadata": {
        "id": "lsFrXqL5TBuC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install package for reading Excels\n",
        "!pip install xlrd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "gW6iKziNGi1r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Basic imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import xlrd\n",
        "\n",
        "# Plots inline\n",
        "%matplotlib inline\n",
        "\n",
        "# Setting plotting styles\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set_style('white')\n",
        "\n",
        "# Displays all cell's output, not just last output\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hKuyi54hMMtA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Environment\n",
        "\n",
        "The default Python environment is within Google Colab (a Google server). I use Google Drive to store all my files. Therefore, I mount my GDrive to the environment, so I can now retrieve and store files directly with my GDrive.\n",
        "\n",
        "**This environment can be changed**. If you are instead working on your local machine, just ensure you have all the required files and are pointing to the correct path.\n",
        "\n",
        "Original data:\n",
        "- streams per ISRC: ***ISRC_1m.txt***\n",
        "- Apple Music international, whether each ISRC-UPC pair is available on Apple Music for each country: ***UMI_AppleMusicTracks.txt***\n",
        "- DiGS Global Rights data: ***2015to18_digs_rights_allstatus.xlsx, 2010to14_digs_rights_allstatus.xlsx, before2010_digs_rights_allstatus.xlsx***\n",
        "- all UPC_ISRC pairings (4.5mil): ***upcs_isrcs_digs_rights_allstatus.tsv***\n",
        "\n",
        "Derived data:\n",
        "- Boolean, long tables of the Rights data (UPCs): ***rights_2015to18_allcountries.csv, rights_2010to14_allcountries.csv, rights_before2010_allcountries.csv***\n",
        "- Apple Music availability per UPC per country (inc number of ISRCs available per UPC): ***international_UPCs_available.csv***"
      ]
    },
    {
      "metadata": {
        "id": "Jis6ipZbS3Ev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mount GDrive to Colab environment\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zQ60k10aA3-6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is so I can save files directly to my GDrive\n",
        "\n",
        "# Install the PyDrive wrapper & import libraries\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HopKaj4TTNi4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Unzip zipped folders, does not need to be repeated\n",
        "\n",
        "# !unzip '/content/drive/My Drive/Personal/Colab Notebooks/Universal/Data/umgglobal_Music.zip' -d '/content/drive/My Drive/Personal/Colab Notebooks/Universal/Data/'\n",
        "# !unzip '/content/drive/My Drive/Personal/Colab Notebooks/Universal/Data/International.zip' -d '/content/drive/My Drive/Personal/Colab Notebooks/Universal/Data/'\n",
        "# !unzip '/content/drive/My Drive/Personal/Colab Notebooks/Universal/Data/upcs_isrcs_digs_rights_allstatus2.tsv.zip' -d '/content/drive/My Drive/Personal/Colab Notebooks/Universal/Data/'\n",
        "\n",
        "# !unzip '/content/drive/My Drive/Personal/Colab Notebooks/Universal/Data/formerly EMI and now GLOBAL.zip' -d '/content/drive/My Drive/Personal/Colab Notebooks/Universal/Data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WAt1MxICUB41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# View files in folder\n",
        "!ls '/content/drive/My Drive/Personal/Colab Notebooks/Universal/Data/'\n",
        "\n",
        "# Create path for data\n",
        "path = '/content/drive/My Drive/Personal/Colab Notebooks/Universal/Data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gT8qbi8kMTld",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data"
      ]
    },
    {
      "metadata": {
        "id": "RsH_U2ZCQrA_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Apple tracks data"
      ]
    },
    {
      "metadata": {
        "id": "7TOF0lrPSieV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load Apple availability data"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "62GmLRFIGi1x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # DON'T NEED TO RERUN\n",
        "\n",
        "# # All tracks on Apple Music\n",
        "\n",
        "# # Select just non-wordy columns so can use only these cols for read_csv (saves memory)\n",
        "# wordy_columns = ['Track_Vendor_id',\n",
        "#                  'Track_Title ',\n",
        "#                  'Primary_Artist_Name',\n",
        "#                  'Track_Audio_Language',\n",
        "#                  'Playlist_Adam_ID ']\n",
        "# nonwordy_apple_columns = [col for col in pd.read_table(path+'UMI_AppleMusicTracks.txt',nrows=5).columns if col not in wordy_columns]\n",
        "\n",
        "# # ---------------------------\n",
        "# # INTERNATIONAL: Read in Apple International ISRCs info (nonwordy columns)\n",
        "# international_apple_df = pd.read_table(path+'UMI_AppleMusicTracks.txt',\n",
        "#                                        usecols=nonwordy_apple_columns,\n",
        "#                                        dtype={'Track_adam_id':str,\n",
        "#                                               'Playlist_UPC':str,\n",
        "#                                               'int':'bool'},\n",
        "#                                        low_memory=False)\n",
        "# international_apple_df.info()\n",
        "# # Converting columns into boolean (saves space)\n",
        "# for country in [col for col in international_apple_df.columns if len(col)==2]:\n",
        "#     international_apple_df[country] = international_apple_df[country].astype('bool')\n",
        "# international_apple_df.info()\n",
        "\n",
        "# # ---------------------------\n",
        "# # GLOBAL: Read in Apple Global ISRCs info (nonwordy columns)\n",
        "# global_international_apple_df = pd.read_table(path+'umgglobal_AppleMusicTracks.txt',\n",
        "#                                               usecols=nonwordy_apple_columns,\n",
        "#                                               dtype={'Track_adam_id':str,\n",
        "#                                                      'Playlist_UPC':str,\n",
        "#                                                      'int':'bool'},\n",
        "#                                               low_memory=False)\n",
        "# global_international_apple_df.info()\n",
        "# # Converting columns into boolean (saves space)\n",
        "# for country in [col for col in global_international_apple_df.columns if len(col)==2]:\n",
        "#     global_international_apple_df[country] = global_international_apple_df[country].astype('bool')\n",
        "# global_international_apple_df.info()\n",
        "\n",
        "# # ---------------------------\n",
        "# # Combine International & Global\n",
        "# international_apple_df = pd.concat(\n",
        "#     [international_apple_df,\n",
        "#      global_international_apple_df],\n",
        "#     ignore_index=True)\n",
        "# del global_international_apple_df #saves RAM\n",
        "# international_apple_df.columns = [col.strip() for col in international_apple_df.columns]\n",
        "# international_apple_df.info()\n",
        "\n",
        "# # ---------------------------\n",
        "# # Fillna UPCs & ISRCs with 'unknown'\n",
        "# international_apple_df['Track_isrc'] = international_apple_df['Track_isrc'].fillna('unknown')\n",
        "# international_apple_df['Playlist_UPC'] = international_apple_df['Playlist_UPC'].fillna('unknown')\n",
        "\n",
        "# # ---------------------------\n",
        "# # Ensure only one row for each UPC-ISRC pair\n",
        "\n",
        "# # Split into two to avoid running out of RAM\n",
        "# UPCs_list = sorted(international_apple_df['Playlist_UPC'].unique())\n",
        "# cutoff = round(len(UPCs_list)/2)\n",
        "# first_half_UPCs = UPCs_list[:cutoff]\n",
        "# second_half_UPCs = UPCs_list[cutoff:]\n",
        "\n",
        "# # Groupby UPC-ISRC, concat the two halves\n",
        "# international_apple_df = pd.concat(\n",
        "#     [international_apple_df[international_apple_df['Playlist_UPC'].isin(first_half_UPCs)].groupby(['Playlist_UPC','Track_isrc']).sum().astype('bool').reset_index(),\n",
        "#      international_apple_df[international_apple_df['Playlist_UPC'].isin(second_half_UPCs)].groupby(['Playlist_UPC','Track_isrc']).sum().astype('bool').reset_index()])\n",
        "\n",
        "# international_apple_df.head(2)\n",
        "# international_apple_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dzsFqWcY8mgI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create reference tables for main Apple work \n",
        "\n",
        "- ***upcs_isrcs_ref_df***: UPC-ISRC pairs which are not present in Apple data but the UPCs are present in the final Rights data\n",
        "- ***UPC_count_sumstreams_df***: num_ISRCs_perUPC & global_ISRCstreams_perUPC"
      ]
    },
    {
      "metadata": {
        "id": "0UV7vFT5YbaJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # DON'T NEED TO RERUN\n",
        "\n",
        "# # Create list of UPC-ISRC pairs that are not present in the Apple data but where the UPCs are present in the rights data\n",
        "# # This is used later to calculate an accurate num_ISRCs_available for each UPC\n",
        "\n",
        "# # NOTE: dtype={'UPC': str} is VERY important as otherwise python reads in the UPCs as integers without the leading zeros\n",
        "\n",
        "# #---------------------\n",
        "# # Extract final UPCs which are represented in the final Rights data\n",
        "# UPC_allyears_allcountries = pd.concat(\n",
        "#     [pd.read_csv(path+'rights_2015to18_allcountries.csv',\n",
        "#                  dtype={'UPC': str},usecols=['UPC']),\n",
        "#      pd.read_csv(path+'rights_2010to14_allcountries.csv',\n",
        "#                  dtype={'UPC': str},usecols=['UPC']),\n",
        "#      pd.read_csv(path+'rights_before2010_allcountries.csv',\n",
        "#                  dtype={'UPC': str},usecols=['UPC'])],\n",
        "#     ignore_index=True)\n",
        "\n",
        "# # This ensures no duplicate UPCs\n",
        "# UPC_allyears_allcountries = UPC_allyears_allcountries.groupby('UPC').size().reset_index().drop(columns=[0])\n",
        "# UPC_allyears_allcountries.head(2)\n",
        "# UPC_allyears_allcountries.info()\n",
        "\n",
        "# #---------------------\n",
        "# # Apple ISRC-UPC pairs\n",
        "# apple_isrc_upc_pairs = pd.concat(\n",
        "#     [pd.read_table(path+'UMI_AppleMusicTracks.txt',\n",
        "#                   usecols=['Track_isrc','Playlist_UPC '], #the space after _UPC is important\n",
        "#                   dtype={'Playlist_UPC':str},\n",
        "#                   low_memory=False),\n",
        "#      pd.read_table(path+'umgglobal_AppleMusicTracks.txt',\n",
        "#                   usecols=['Track_isrc','Playlist_UPC '], #the space after _UPC is important\n",
        "#                   dtype={'Playlist_UPC':str},\n",
        "#                   low_memory=False)],ignore_index=True)\n",
        "# apple_isrc_upc_pairs.info()\n",
        "\n",
        "# # Rid the column names of spaces before or after the colname\n",
        "# apple_isrc_upc_pairs.columns = [col.strip() for col in apple_isrc_upc_pairs.columns]\n",
        "\n",
        "# # Ensures no duplicate UPC-ISRC pairs\n",
        "# apple_isrc_upc_pairs = apple_isrc_upc_pairs.groupby(['Playlist_UPC','Track_isrc'],as_index=False).size().reset_index().drop(columns=[0])\n",
        "\n",
        "# # Give flag to these UPC-ISRC pairs as this will be used next to deselect these existing pairs\n",
        "# apple_isrc_upc_pairs['apple_flag'] = True \n",
        "# apple_isrc_upc_pairs.info()\n",
        "# apple_isrc_upc_pairs.head(2)\n",
        "\n",
        "# #---------------------\n",
        "# # ISRC-UPC pairs base data from Universal\n",
        "# upcs_isrcs_ref_df = pd.read_table(path+'upcs_isrcs_digs_rights_allstatus.tsv',\n",
        "#                                   dtype={0:'str'},\n",
        "#                                   names=['UPC','ISRC'])\n",
        "# upcs_isrcs_ref_df.info()\n",
        "\n",
        "# # Select only UPCs which are in the final Rights data\n",
        "# upcs_isrcs_ref_df = pd.merge(upcs_isrcs_ref_df,\n",
        "#                              UPC_allyears_allcountries,\n",
        "#                              how='right',\n",
        "#                              on='UPC')\n",
        "# upcs_isrcs_ref_df.info()\n",
        "# del UPC_allyears_allcountries #saves space\n",
        "\n",
        "# # Keep only UPC-ISRC pairs which are not already in the Apple data\n",
        "# upcs_isrcs_ref_df = pd.merge(upcs_isrcs_ref_df,\n",
        "#                              apple_isrc_upc_pairs,\n",
        "#                              how='left',\n",
        "#                              left_on=['UPC','ISRC'],\n",
        "#                              right_on=['Playlist_UPC','Track_isrc'])\n",
        "# upcs_isrcs_ref_df = upcs_isrcs_ref_df[upcs_isrcs_ref_df['apple_flag'].isnull()]\n",
        "# upcs_isrcs_ref_df.info()\n",
        "# del apple_isrc_upc_pairs #saves space\n",
        "\n",
        "# # Select only the full UPC-ISRC columns, dropna covers the fewer ISRCs which are null\n",
        "# upcs_isrcs_ref_df = upcs_isrcs_ref_df[['UPC','ISRC']].dropna()\n",
        "\n",
        "# upcs_isrcs_ref_df.head(2)\n",
        "# upcs_isrcs_ref_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BgS1upayG_wP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # DON'T NEED TO RERUN\n",
        "\n",
        "# # Create table of global_streams_ofISRCs_onUPC as proxy for popularity\n",
        "\n",
        "# # Number of streams per ISRC across all platforms - proxy for popularity\n",
        "# isrc_streams_df = pd.read_csv(path+'ISRC_1m.txt')\n",
        "# isrc_streams_df.head(2)\n",
        "# isrc_streams_df.info()\n",
        "\n",
        "# #---------------------\n",
        "# # UPC-ISRC pairs base data from Universal\n",
        "# UPC_count_sumstreams_df = pd.read_table(path+'upcs_isrcs_digs_rights_allstatus.tsv',\n",
        "#                                         dtype={0:'str'},\n",
        "#                                         names=['UPC','ISRC'])\n",
        "# UPC_count_sumstreams_df.info()\n",
        "\n",
        "# #---------------------\n",
        "# # Merge ISRC streams onto UPC-ISRCs table, fill total_streams=0 if no matching ISRC available\n",
        "# # Drop row if no streams for that ISRC\n",
        "# UPC_count_sumstreams_df = pd.merge(UPC_count_sumstreams_df,\n",
        "#                                    isrc_streams_df,\n",
        "#                                    how='left',\n",
        "#                                    left_on='ISRC',\n",
        "#                                    right_on='isrc').drop(columns=['isrc']).fillna(0)\n",
        "# del isrc_streams_df #saves space\n",
        "\n",
        "# #---------------------\n",
        "# # Groupby UPC to get num_ISRCs_per_UPC and global_streams_ofISRCs_onUPC\n",
        "# UPC_count_sumstreams_df = UPC_count_sumstreams_df.groupby('UPC').agg({'UPC':'count',\n",
        "#                                                                       'total_streams':'sum'})\n",
        "# UPC_count_sumstreams_df.rename(columns={'UPC':'num_ISRCs_per_UPC',\n",
        "#                                         'total_streams':'global_streams_ofISRCs_onUPC'},\n",
        "#                                inplace=True)\n",
        "\n",
        "# UPC_count_sumstreams_df.head(2)\n",
        "# UPC_count_sumstreams_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NbI4LHIhH0Ai",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create UPC-level table from ISRC-level Apple availability table"
      ]
    },
    {
      "metadata": {
        "id": "nsxKLpJH9VD8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # DON'T NEED TO RERUN\n",
        "\n",
        "# # 1) Groupby ISRC to get availablity for each ISRC (across all UPCs) for each country\n",
        "# # 2) Merge that with the UPC-ISRC pairs which are not in Apple Music - groupby UPC straight away to save space\n",
        "# # 3) Merge the ISRC availability table with the original Apple table\n",
        "\n",
        "# # 1) Groupby ISRC, so for bool ISRC_availablility for each ISRC for each country (true if ISRC available with any UPC)\n",
        "# international_apple_ISRCs_df = international_apple_df.groupby('Track_isrc').sum().astype('bool')\n",
        "# international_apple_ISRCs_df.columns = ['ISRC_available_in{}'.format(country) for country in international_apple_ISRCs_df.columns]\n",
        "# international_apple_ISRCs_df.info()\n",
        "\n",
        "# # #---------------------\n",
        "# # 2) For the UPC-ISRC pairs which are not in Apple Music, merge on whether the ISRC is available in each country\n",
        "# # Groupby UPC straight away to save space. The columns now equate to how many ISRCs are availble for each UPC for each country (for the UPC-ISRC pairs not in Apple Music)\n",
        "# upcs_isrcs_ref_df = pd.merge(upcs_isrcs_ref_df,\n",
        "#                              international_apple_ISRCs_df,\n",
        "#                              how='left',\n",
        "#                              left_on='ISRC',\n",
        "#                              right_index=True).dropna().groupby('UPC').sum()\n",
        "# upcs_isrcs_ref_df.info()\n",
        "\n",
        "# # Drop ISRC column as no longer important\n",
        "# upcs_isrcs_ref_df.drop(columns=['ISRC'],inplace=True)\n",
        "\n",
        "# # Rename this column so in concats well below\n",
        "# upcs_isrcs_ref_df = upcs_isrcs_ref_df.reset_index().rename(columns={'UPC':'Playlist_UPC'}).set_index('Playlist_UPC')\n",
        "# upcs_isrcs_ref_df.info()\n",
        "# upcs_isrcs_ref_df.head(2)\n",
        "\n",
        "# # #---------------------\n",
        "# # 3) Merge original Apple ISRC table with whether that ISRC is available for any UPC\n",
        "# international_apple_ISRCs_df = pd.merge(international_apple_df,\n",
        "#                                         international_apple_ISRCs_df,\n",
        "#                                         how='left',\n",
        "#                                         left_on='Track_isrc',\n",
        "#                                         right_index=True)\n",
        "# international_apple_ISRCs_df.head(2)\n",
        "# international_apple_ISRCs_df.info()\n",
        "# del international_apple_df #saves space"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SoIIoOk3_tEa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # DON'T NEED TO RERUN\n",
        "\n",
        "# # 1) Groupby UPC - for each UPC for each country: i) have a boolean indicator of whether UPC is available; ii) integer of many ISRCs of available for that UPC\n",
        "# # 2) For each country: rename columns, make UPC_available_in columns boolean\n",
        "# # 3) Concat the Apple-derived and non-Apple-derived tables\n",
        "# # 4) Groupby UPC to solve the multi-UPC issue\n",
        "# # 5) Merge in num_ISRCs_per_UPC & global_streams_ofISRCs_onUPC\n",
        "\n",
        "# # #---------------------\n",
        "# # 1) Groupby UPC - for each UPC for each country: i) have a boolean indicator of whether UPC is available; ii) integer of many ISRCs of available for that UPC\n",
        "# international_UPCs_available_df = international_apple_ISRCs_df.groupby('Playlist_UPC').sum()\n",
        "# international_UPCs_available_df.info()\n",
        "# del international_apple_ISRCs_df #saves space\n",
        "\n",
        "# # #---------------------\n",
        "# # 2) For each country: rename columns, make UPC_available_in columns boolean\n",
        "# for country in [col for col in international_UPCs_available_df.columns if len(col)==2]:\n",
        "#     international_UPCs_available_df.rename(columns={country:'UPC_available_in{}'.format(country),\n",
        "#                                                     'ISRC_available_in{}'.format(country):'num_ISRCs_available_{}'.format(country)},\n",
        "#                                            inplace=True)\n",
        "#     # Make bool columns - if ISRC present for any UPC, then col = True\n",
        "#     international_UPCs_available_df['UPC_available_in{}'.format(country)] = international_UPCs_available_df['UPC_available_in{}'.format(country)].astype('bool')\n",
        "    \n",
        "#     upcs_isrcs_ref_df.rename(columns={'ISRC_available_in{}'.format(country):'num_ISRCs_available_{}'.format(country)},\n",
        "#                              inplace=True)\n",
        "# upcs_isrcs_ref_df.head(2)\n",
        "\n",
        "# # #---------------------\n",
        "# # international_UPCs_available_df: is Apple-derived, for each UPC for each country, bool UPC_available & integer num_ISRCs_available_\n",
        "# # upcs_isrcs_ref_df: is non-Apple-derived, for each UPC for each country, & integer num_ISRCs_available_ (no bool UPC_available as none of the UPC_ISRC pairs are available by design)\n",
        "\n",
        "# # 3) Concat the tables over each other, matching the num_ISRCs_available_ columns, and filling as false the UPC_available columns\n",
        "# # There are repeated UPCs, which is fixed later by the groupby\n",
        "# international_UPCs_available_df = pd.concat(\n",
        "#     [international_UPCs_available_df.reset_index(),\n",
        "#      upcs_isrcs_ref_df.reset_index()],\n",
        "#     ignore_index=True).fillna(False)\n",
        "# del upcs_isrcs_ref_df #saves space\n",
        "# international_UPCs_available_df.head(2)\n",
        "# international_UPCs_available_df.info()\n",
        "\n",
        "# # Converts the num_ISRCs_available_ columns into integers so they can be summed in the groupby\n",
        "# for country in [col[-2:] for col in international_UPCs_available_df.columns if 'ISRCs' in col]:\n",
        "#     international_UPCs_available_df['num_ISRCs_available_{}'.format(country)] = international_UPCs_available_df['num_ISRCs_available_{}'.format(country)].astype('int')\n",
        "# international_UPCs_available_df.info()\n",
        "\n",
        "# # #---------------------\n",
        "# # 4) This solves the multi-UPC issue- groupby UPC & sum\n",
        "# # All UPC_available columns are False for upcs_isrcs_ref_df UPCs, so these UPCs are unaffected.\n",
        "# # The num_ISRCs_available_ columns sum to the true ISRC availability per UPC, even for UPCs not represented in the Apple table\n",
        "# international_UPCs_available_df = international_UPCs_available_df.groupby('Playlist_UPC').sum()\n",
        "# international_UPCs_available_df.info()\n",
        "# international_UPCs_available_df.head(2)\n",
        "\n",
        "# # #---------------------\n",
        "# # 5) Merge in num_ISRCs_per_UPC & global_streams_ofISRCs_onUPC\n",
        "# international_UPCs_available_df = pd.merge(international_UPCs_available_df,\n",
        "#                                            UPC_count_sumstreams_df,\n",
        "#                                            how='left',\n",
        "#                                            left_index=True,\n",
        "#                                            right_index=True)\n",
        "# del UPC_count_sumstreams_df #saves space\n",
        "# international_UPCs_available_df.head(2)\n",
        "# international_UPCs_available_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VN08m0nZ6uFe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # DON'T NEED TO RERUN\n",
        "\n",
        "# # Create & upload file to Google Drive - international_UPCs_df\n",
        "\n",
        "# international_UPCs_available_df.to_csv('international_UPCs_available.csv', index=True)\n",
        "# uploaded = drive.CreateFile({'title': 'international_UPCs_available.csv'})\n",
        "# uploaded.SetContentFile('international_UPCs_available.csv')\n",
        "# uploaded.Upload()\n",
        "# print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ODTxwVyq692H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reupload Apple reference table"
      ]
    },
    {
      "metadata": {
        "id": "BZw2Fcz27Gb2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reupload availability table\n",
        "international_UPCs_available_df = pd.read_csv(path+'international_UPCs_available (1).csv',\n",
        "                                              dtype={'UPC':'str'},\n",
        "                                              low_memory=False\n",
        "                                             ).set_index('Playlist_UPC')\n",
        "\n",
        "# international_UPCs_available_df = pd.read_csv(path+'international_UPCs_available.csv',\n",
        "#                                               dtype={'UPC':'str'},\n",
        "#                                               low_memory=False\n",
        "#                                              ).set_index('Playlist_UPC')\n",
        "international_UPCs_available_df.head(2)\n",
        "international_UPCs_available_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SkrsT1ZYC_Zg"
      },
      "cell_type": "markdown",
      "source": [
        "## Rights data"
      ]
    },
    {
      "metadata": {
        "id": "I7WKQkI0AQZo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create wide Rights data of boolean columns\n",
        "\n",
        "Only to be run once. Takes ~4hrs."
      ]
    },
    {
      "metadata": {
        "id": "sBhSOcEkZ3N0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # DOES NOT NEED TO BE RERUN\n",
        "\n",
        "# # This code takes the Rights data for all UPCs\n",
        "# # At the beginning there is, for each UPC, a string of two-letter country codes with rights for each of Legal / Marketing / Optin\n",
        "# # This script creates bollean columns for each country for each right, of whether that UPC has that right\n",
        "\n",
        "# # This code takes a looong time to run, ~4hrs for the entire for loop\n",
        "# # It is separated by various For loops in order to stay below the RAM limit (11GB)\n",
        "# # This only needs to be done ONCE. It saves each year_range output to GDrive, which are then reuploaded in the next section.\n",
        "\n",
        "# # Within the For loop:\n",
        "# # 1) Read in the Rights data\n",
        "# # 2) Keep only albums & single (not ringtones & videos)\n",
        "# # 3) Split string by comma into a list of all countries\n",
        "# # 4) Loop to create boolean columns of whether the UPC has the right\n",
        "# # 5) Create & upload file to Google Drive\n",
        "\n",
        "# # ----------------\n",
        "# # Separated into 3 manageable sections due to large table size\n",
        "# rights_df_dict = {}\n",
        "# year_ranges = ['2015to18','2010to14','before2010']\n",
        "# for year in year_ranges:\n",
        "\n",
        "#     # 1) Legal & marketing rights, and opt-in, for each UPC\n",
        "#     rights_df_dict[year] = pd.read_excel(path+'{}_digs_rights_allstatus.xlsx'.format(year),\n",
        "#                               dtype={'UPC': str}\n",
        "#                              ).set_index('UPC')\n",
        "    \n",
        "#     # Strip leading & lagging space from column names \n",
        "#     rights_df_dict[year].columns = [col.strip() for col in rights_df_dict[year].columns]\n",
        "#     rights_df_dict[year].info()\n",
        "    \n",
        "#     # ----------------\n",
        "#     # Lower case to ensure no issues with case non-matching\n",
        "#     rights_df_dict[year]['Product Configuration'] = rights_df_dict[year]['Product Configuration'].apply(lambda s: s.lower())\n",
        "    \n",
        "#     # 2) Keep only albums & single (not ringtones & videos)\n",
        "#     rights_df_dict[year]['single'] = rights_df_dict[year]['Product Configuration'].apply(lambda x: \n",
        "#                                                                    True if 'single' in x.lower() \n",
        "#                                                                    and 'video' not in x.lower()\n",
        "#                                                                    and 'album' not in x.lower()\n",
        "#                                                                    else False)\n",
        "#     rights_df_dict[year]['album'] = rights_df_dict[year]['Product Configuration'].apply(lambda x: \n",
        "#                                                                   True if ('album' in x.lower() \n",
        "#                                                                            or 'bundle' in x.lower())\n",
        "#                                                                   and 'video' not in x.lower()\n",
        "#                                                                   and 'single' not in x.lower()\n",
        "#                                                                   else False)\n",
        "#     rights_df_dict[year] = rights_df_dict[year][rights_df_dict[year]['single'] | rights_df_dict[year]['album']]\n",
        "#     rights_df_dict[year].info()\n",
        "    \n",
        "#     # ----------------\n",
        "#     # Keep only relevant columns\n",
        "#     rights_df_dict[year] = rights_df_dict[year][['Legal Territories List','Marketing Territories List','Opt In List']]\n",
        "\n",
        "#     # 3) Making each string of countries a list within each cell for each UPC\n",
        "#     rights_df_dict[year].replace('-', 'none', inplace=True)\n",
        "#     for col in rights_df_dict[year].columns:\n",
        "#         rights_df_dict[year][col] = rights_df_dict[year][col].apply(lambda x: x.split(','))\n",
        "#     rights_df_dict[year].head(2)\n",
        "#     rights_df_dict[year].info()\n",
        "    \n",
        "#     # ----------------\n",
        "#     # Creates lists of all countries, and country_right interactions\n",
        "#     list_of_countries = list(rights_df_dict[year]['Legal Territories List'][rights_df_dict[year]['Legal Territories List'].apply(lambda x: len(x)).idxmax()])\n",
        "#     print(list_of_countries)\n",
        "    \n",
        "    \n",
        "#     # To save memory: split into three separate for loops so I can drop the reference col each time\n",
        "#     # 4) Loop to create boolean columns of whether the UPC has the right\n",
        "    \n",
        "#     # Legal rights\n",
        "#     for country in list_of_countries+['none']:\n",
        "#         print(country, '{} legal starting'.format(year))\n",
        "#         rights_df_dict[year]['{}_legal'.format(country)] = rights_df_dict[year].apply(lambda row: \n",
        "#                                                                                       True if country in row['Legal Territories List'] \n",
        "#                                                                                       else False,\n",
        "#                                                                                       axis=1)\n",
        "#         print(country, '{} legal ended'.format(year))   \n",
        "#     rights_df_dict[year].drop(columns=['Legal Territories List'],\n",
        "#                    inplace=True)\n",
        "\n",
        "#     # Marketing rights\n",
        "#     for country in list_of_countries+['none']:\n",
        "#         print(country, '{} marketing starting'.format(year))\n",
        "#         rights_df_dict[year]['{}_marketing'.format(country)] = rights_df_dict[year].apply(lambda row: \n",
        "#                                                                                           True if country in row['Marketing Territories List'] \n",
        "#                                                                                           else False,\n",
        "#                                                                                           axis=1)\n",
        "#         print(country, '{} marketing ended'.format(year))\n",
        "#     rights_df_dict[year].drop(columns=['Marketing Territories List'],\n",
        "#                    inplace=True)\n",
        "\n",
        "#     # Opt-in\n",
        "#     for country in list_of_countries+['none']:\n",
        "#         print(country, '{} optin starting'.format(year))\n",
        "#         rights_df_dict[year]['{}_optin'.format(country)] = rights_df_dict[year].apply(lambda row: \n",
        "#                                                                                       True if country in row['Opt In List'] \n",
        "#                                                                                       else False,\n",
        "#                                                                                       axis=1)\n",
        "#         print(country, '{} optin ended'.format(year))\n",
        "#     rights_df_dict[year].drop(columns=['Opt In List'],\n",
        "#                    inplace=True)\n",
        "    \n",
        "#     rights_df_dict[year].info()\n",
        "    \n",
        "#     # ----------------\n",
        "#     # 5) Create & upload file to Google Drive\n",
        "#     rights_df_dict[year].to_csv('rights_{}_allcountries.csv'.format(year), index=True)\n",
        "#     uploaded = drive.CreateFile({'title': 'rights_{}_allcountries.csv'.format(year)})\n",
        "#     uploaded.SetContentFile('rights_{}_allcountries.csv'.format(year))\n",
        "#     uploaded.Upload()\n",
        "#     print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "    \n",
        "#     del rights_df_dict[year] #saves RAM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Q3kR3cfwC_Zx"
      },
      "cell_type": "markdown",
      "source": [
        "### Reupload wide Rights data of boolean columns"
      ]
    },
    {
      "metadata": {
        "id": "CHLMAkBX3XJk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reupload & concat all Rights information\n",
        "\n",
        "# Some year_ranges have columns which are not present for all year_ranges. This is if a country code has changed etc. These columns are fillna'd as False\n",
        "reuploaded_rights_all_countries_df = pd.concat(\n",
        "    [pd.read_csv(path+'rights_2015to18_allcountries.csv',\n",
        "                 dtype={'UPC': str}),\n",
        "     pd.read_csv(path+'rights_2010to14_allcountries.csv',\n",
        "                 dtype={'UPC': str}),\n",
        "     pd.read_csv(path+'rights_before2010_allcountries.csv',\n",
        "                 dtype={'UPC': str})],\n",
        "    ignore_index=True).set_index('UPC').fillna('False').astype('bool').reset_index().dropna() #drops NaN UPCs\n",
        "reuploaded_rights_all_countries_df.head(2)\n",
        "reuploaded_rights_all_countries_df.info()\n",
        "\n",
        "# ---------------------------\n",
        "# Ensure only one row for each UPC-ISRC pair\n",
        "\n",
        "# Split into two to avoid running out of RAM\n",
        "UPCs_list = sorted(reuploaded_rights_all_countries_df['UPC'].unique())\n",
        "cutoff = round(len(UPCs_list)/2)\n",
        "first_half_UPCs = UPCs_list[:cutoff]\n",
        "second_half_UPCs = UPCs_list[cutoff:]\n",
        "\n",
        "# Groupby UPC-ISRC, concat the two halves\n",
        "reuploaded_rights_all_countries_df = pd.concat(\n",
        "    [reuploaded_rights_all_countries_df[reuploaded_rights_all_countries_df['UPC'].isin(first_half_UPCs)].groupby('UPC').sum().astype('bool'),\n",
        "     reuploaded_rights_all_countries_df[reuploaded_rights_all_countries_df['UPC'].isin(second_half_UPCs)].groupby('UPC').sum().astype('bool')])\n",
        "\n",
        "reuploaded_rights_all_countries_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "o1GXd0RYC_Z5"
      },
      "cell_type": "markdown",
      "source": [
        "### Rights wordy info\n",
        "\n",
        "Create table with all wordy information (Artist,Title,Label etc) for each UPC (from original Rights spreadsheets)"
      ]
    },
    {
      "metadata": {
        "id": "r8p3mmZg4YuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creates table of wordyinfo for each UPC: Artist / Title / ReleaseDate / Label etc\n",
        "\n",
        "# Legal & marketing rights, and opt-in, for each UPC\n",
        "# There exist duplicate UPCs but this is corrected at the end because it takes too long without first removing the uneeded UPCs\n",
        "rights_wordyinfo_df = pd.concat(\n",
        "    [pd.read_excel(path+'2015to18_digs_rights_allstatus.xlsx',\n",
        "                   dtype={'UPC': str}),\n",
        "     pd.read_excel(path+'2010to14_digs_rights_allstatus.xlsx',\n",
        "                   dtype={'UPC': str}),\n",
        "     pd.read_excel(path+'before2010_digs_rights_allstatus.xlsx',\n",
        "                   dtype={'UPC': str})],\n",
        "    ignore_index=True)\n",
        "rights_wordyinfo_df.columns = [col.strip() for col in rights_wordyinfo_df.columns]\n",
        "rights_wordyinfo_df.drop(columns=['Opt In List','Marketing Territories List','Legal Territories List'], #these are the non-wordy columns\n",
        "                         inplace=True)\n",
        "rights_wordyinfo_df.info()\n",
        "\n",
        "# ------------------------\n",
        "# Make everything lower case to avoid case mismatch\n",
        "rights_wordyinfo_df = rights_wordyinfo_df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
        "\n",
        "# Create boolean columns for each of Single and Album\n",
        "rights_wordyinfo_df['single'] = rights_wordyinfo_df['Product Configuration'].apply(lambda x: \n",
        "                                                                                   True if 'single' in x.lower() \n",
        "                                                                                   and 'video' not in x.lower()\n",
        "                                                                                   and 'album' not in x.lower()\n",
        "                                                                                   else False)\n",
        "rights_wordyinfo_df['album'] = rights_wordyinfo_df['Product Configuration'].apply(lambda x: \n",
        "                                                                                  True if ('album' in x.lower() \n",
        "                                                                                           or 'bundle' in x.lower())\n",
        "                                                                                  and 'video' not in x.lower()\n",
        "                                                                                  and 'single' not in x.lower()\n",
        "                                                                                  else False)\n",
        "# Keep only Singles & Albums (not ringtones or videos)\n",
        "rights_wordyinfo_df = rights_wordyinfo_df[rights_wordyinfo_df['single'] | rights_wordyinfo_df['album']]\n",
        "rights_wordyinfo_df.info()\n",
        "\n",
        "# Remove duplicate UPCs (.first() takes an annoying amount of time)\n",
        "rights_wordyinfo_df = rights_wordyinfo_df.groupby('UPC').first()\n",
        "rights_wordyinfo_df.info()\n",
        "\n",
        "# ------------------------\n",
        "# Fill the few empty Artist & Titles with 'unknown'\n",
        "rights_wordyinfo_df['Artist'] = rights_wordyinfo_df['Artist'].fillna('unknown')\n",
        "rights_wordyinfo_df['Title'] = rights_wordyinfo_df['Title'].fillna('unknown')\n",
        "\n",
        "# Create boolean flag of released before 2018\n",
        "rights_wordyinfo_df['release_before_2018'] = rights_wordyinfo_df['Release Date'].apply(lambda x: \n",
        "                                                                                       True if x.year < 2018 \n",
        "                                                                                       else False)\n",
        "\n",
        "# Create binary column from Status, 'existing' or 'voided' (voided=cancelled,deleted etc)\n",
        "rights_wordyinfo_df['binary_status'] = rights_wordyinfo_df['Status'].apply(lambda x: \n",
        "                                                                           'existing' if x in ['delivered','scheduled','final'] \n",
        "                                                                           else 'voided')\n",
        "\n",
        "rights_wordyinfo_df.info()\n",
        "rights_wordyinfo_df.head(2)\n",
        "\n",
        "# ------------------------\n",
        "# Add on bool column of whether they have duplicate Artist-Title\n",
        "artist_title_duplicates_df = pd.DataFrame(\n",
        "    rights_wordyinfo_df.groupby(['Artist','Title']).size()\n",
        ").rename(columns={0:'duplicate_artist_title'})\n",
        "artist_title_duplicates_df['duplicate_artist_title'] = artist_title_duplicates_df['duplicate_artist_title'] > 1\n",
        "\n",
        "rights_wordyinfo_df = pd.merge(rights_wordyinfo_df.reset_index(),\n",
        "                               artist_title_duplicates_df.reset_index(),\n",
        "                               how='left',\n",
        "                               on=['Artist','Title']\n",
        "                              ).set_index('UPC')\n",
        "rights_wordyinfo_df.info()\n",
        "del artist_title_duplicates_df #saves RAM\n",
        "\n",
        "# ------------------------\n",
        "# Create core_columns for per-country table\n",
        "core_columns = list(rights_wordyinfo_df.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V7FHVmo1_Bty",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Base UPC table for all countries"
      ]
    },
    {
      "metadata": {
        "id": "V38e1Y32LAmo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Using the reuploaded Rights data as the base, merge on Apple availablity information and Rights wordy info\n",
        "# This creates the monster reference table for all countries\n",
        "\n",
        "# Merge Rights data & derived Apple availability data, for each UPC for each country\n",
        "international_UPCs_df = pd.merge(reuploaded_rights_all_countries_df.reset_index(),\n",
        "                                 international_UPCs_available_df,\n",
        "                                 how='left',\n",
        "                                 left_on='UPC',\n",
        "                                 right_index=True).set_index('UPC')\n",
        "international_UPCs_df.info()\n",
        "international_UPCs_df.head(2)\n",
        "del reuploaded_rights_all_countries_df #save space\n",
        "del international_UPCs_available_df #save space\n",
        "\n",
        "# ------------------------\n",
        "# Merge wordy info\n",
        "international_UPCs_df = pd.merge(international_UPCs_df,\n",
        "                                 rights_wordyinfo_df,\n",
        "                                 how='left',\n",
        "                                 left_index=True,\n",
        "                                 right_index=True)\n",
        "international_UPCs_df.info()\n",
        "international_UPCs_df.head(2)\n",
        "del rights_wordyinfo_df #saves RAM\n",
        "\n",
        "# ------------------------\n",
        "# Create list of all country codes from apple data \n",
        "international_columns_list = [col for col in pd.read_csv(path+'UMI_AppleMusicTracks.txt',sep='\\t',nrows=5).columns if len(col)==2]\n",
        "\n",
        "# Create proportion of UPC already on store\n",
        "for country in international_columns_list:\n",
        "    international_UPCs_df['propISRCs_onstore_{}'.format(country)] = international_UPCs_df['num_ISRCs_available_{}'.format(country)] / international_UPCs_df['Track Count']\n",
        "    \n",
        "# ------------------------\n",
        "# Fill nans\n",
        "international_UPCs_df['global_streams_ofISRCs_onUPC'] = international_UPCs_df['global_streams_ofISRCs_onUPC'].fillna(0)\n",
        "for country in international_columns_list:\n",
        "    international_UPCs_df['num_ISRCs_available_{}'.format(country)] = international_UPCs_df['num_ISRCs_available_{}'.format(country)].fillna(0)\n",
        "    international_UPCs_df['propISRCs_onstore_{}'.format(country)] = international_UPCs_df['propISRCs_onstore_{}'.format(country)].fillna(0) #happens if Track Count is empty\n",
        "    international_UPCs_df['UPC_available_in{}'.format(country)] = international_UPCs_df['UPC_available_in{}'.format(country)].fillna(False)\n",
        "\n",
        "# ------------------------\n",
        "international_UPCs_df.head(2)\n",
        "international_UPCs_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1LQ2K7PnKS3i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Create & upload file to Google Drive - international_UPCs_df\n",
        "\n",
        "# international_UPCs_df.to_csv('international_UPCs_base.csv', index=True)\n",
        "# !zip ZIP_international_UPCs_base.zip international_UPCs_base.csv\n",
        "# uploaded = drive.CreateFile({'title': 'ZIP_international_UPCs_base.zip'})\n",
        "# uploaded.SetContentFile('ZIP_international_UPCs_base.zip')\n",
        "# uploaded.Upload()\n",
        "# print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "# !mv ZIP_international_UPCs_base.zip '/content/drive/My Drive/Personal/Colab Notebooks/Universal/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-DcmiGuyX5ju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Outputs for GB"
      ]
    },
    {
      "metadata": {
        "id": "Q3yMMu0H5_e6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# defined from rights_wordyinfo_df (end of code that creates that table)\n",
        "# may need to define core_columns if don't run rights_wordyinfo_df code\n",
        "core_columns = core_columns + ['num_ISRCs_per_UPC','global_streams_ofISRCs_onUPC']\n",
        "\n",
        "# Create empty dict for \n",
        "country_data = {}\n",
        "\n",
        "# # ------------------------\n",
        "# # Can upload UPC_base direct from saved, rather than creating UPC_base\n",
        "# # Not really recommended, but quicker\n",
        "# international_UPCs_df = pd.read_csv(path+'20181211_international_UPCs_base.csv',\n",
        "#                                     dtype={'UPC': str},\n",
        "#                                     low_memory=False).set_index('UPC')\n",
        "# international_UPCs_df.info()\n",
        "# international_UPCs_df.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W-4Av5AiYL-8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get just GB-relevant columns for all UPCs\n",
        "# And create GB-specific numbers matrix\n",
        "\n",
        "country_data['gb'] = international_UPCs_df[[col for col in international_UPCs_df.columns if 'GB' in col]+core_columns].copy()\n",
        "country_data['gb'].info()\n",
        "country_data['gb'].head(2)\n",
        "\n",
        "# ------------------------\n",
        "# Group by all necessary columns to create matrix figures\n",
        "GB_UPCs_matrix = pd.DataFrame(\n",
        "    international_UPCs_df.groupby(\n",
        "        ['GB_legal',\n",
        "         'GB_marketing',\n",
        "         'GB_optin',\n",
        "         'UPC_available_inGB',\n",
        "         'album',\n",
        "         'single',\n",
        "         'duplicate_artist_title',\n",
        "         'release_before_2018',\n",
        "         'binary_status']\n",
        "    ).size()).rename(columns={0:'size'}).reset_index()\n",
        "\n",
        "# Round for nicer figures\n",
        "GB_UPCs_matrix['size'] = GB_UPCs_matrix['size'].apply(lambda x: round(x,-2))\n",
        "\n",
        "# ------------------------\n",
        "# Create 'category' column for legal-marketing-optin-available matrix \n",
        "def create_category(row):\n",
        "    if not row['GB_legal']:\n",
        "        return 'no_legal'\n",
        "    elif (row['GB_legal'] and not row['GB_marketing']):\n",
        "        return 'legal_nomarketing'\n",
        "    elif (row['GB_legal'] and row['GB_marketing'] and not row['GB_optin']):\n",
        "        return 'legal_marketing_no_optin'\n",
        "    elif (row['GB_legal'] and row['GB_marketing'] and row['GB_optin'] and not row['UPC_available_inGB'] and row['release_before_2018']):\n",
        "        return 'legal_marketing_optin_notavailable_before2018'\n",
        "    elif (row['GB_legal'] and row['GB_marketing'] and row['GB_optin'] and not row['UPC_available_inGB'] and not row['release_before_2018']):\n",
        "        return 'legal_marketing_optin_notavailable_2018onwards'\n",
        "    else:\n",
        "        return 'all_in'\n",
        "GB_UPCs_matrix['category'] = GB_UPCs_matrix.apply(create_category,axis=1)\n",
        "\n",
        "# ------------------------\n",
        "# Pivot to nice table format\n",
        "GB_UPCs_matrix = pd.pivot_table(GB_UPCs_matrix,\n",
        "                                values='size',\n",
        "                                index=['album','duplicate_artist_title','binary_status'],\n",
        "                                columns=['category'],\n",
        "                                aggfunc='sum')\n",
        "# Sum each row\n",
        "GB_UPCs_matrix['sum'] = GB_UPCs_matrix.sum(axis=1)\n",
        "\n",
        "# Reorder columns, from all_in to no_legal\n",
        "GB_UPCs_matrix = GB_UPCs_matrix[['all_in',\n",
        "                                 'legal_marketing_optin_notavailable_2018onwards',\n",
        "                                 'legal_marketing_optin_notavailable_before2018',\n",
        "                                 'legal_marketing_no_optin',\n",
        "                                 'legal_nomarketing',\n",
        "                                 'no_legal',\n",
        "                                 'sum']]\n",
        "\n",
        "# Show matrix, and show sum for each column in matrix\n",
        "GB_UPCs_matrix\n",
        "GB_UPCs_matrix.sum()\n",
        "\n",
        "# # ------------------------\n",
        "# # Create & upload file to Google Drive - GB_UPC_data.csv\n",
        "# country_data['gb'].to_csv('GB_UPC_data.csv')\n",
        "# uploaded = drive.CreateFile({'title': 'GB_UPC_data.csv'})\n",
        "# uploaded.SetContentFile('GB_UPC_data.csv')\n",
        "# uploaded.Upload()\n",
        "# print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "# # ------------------------\n",
        "# # Create & upload file to Google Drive - GB_aggregatenumbers.csv\n",
        "# GB_UPCs_matrix.to_csv('GB_aggregatenumbers.csv')\n",
        "# uploaded = drive.CreateFile({'title': 'GB_aggregatenumbers.csv'})\n",
        "# uploaded.SetContentFile('GB_aggregatenumbers.csv')\n",
        "# uploaded.Upload()\n",
        "# print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xZCzqVqlSEXn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ]
    },
    {
      "metadata": {
        "id": "Ipoz5YdN18j4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}