{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Revolut_fraudster.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "I5ERs_ewhO9k",
        "jhSfj59AhfhM",
        "2eUiNT8Anqay",
        "c1lPEO8ztvZk",
        "kH8RbfvTdDK7",
        "8GEH6lX3dHCW",
        "9jSVaBnf-Zm5",
        "QP0KBlIsAr5X",
        "3Ldmb_NfFX6Q",
        "Evj1RxCQN3Gm",
        "zljieTWoDqwB",
        "C6cI3MT0T73w",
        "8lPlSnhZahT_",
        "77cx3Z_WUkou",
        "e5Bkkj3JdlhI",
        "tL6jdlLbKCTK"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/richard-cartwright/personal/blob/master/Revolut_fraudster.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "I5ERs_ewhO9k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SUMMARY\n",
        "\n",
        "Q1: I use SQLalchemy to ETL data into a local Postgres database\n",
        "\n",
        "Q2: I filter the data so to extract users whose first transaction was a successful card payment over $10\n",
        "\n",
        "Q3: I design a system to identify fraudsters\n",
        "- I first engineer user-specific features, then transaction-derived features for each user\n",
        "- I run basic models (LogReg & out-of-the-box RandomForest) to get a baseline\n",
        "- I tackle Class Imbalance: only 3% of users are fraudsters. This means I must use accuracy metrics which account for low recall (high false negative). I use Brier score, AUC ROC, F1 score.\n",
        "- I use the model's output probabilities to decide what action to take. I draw intuitive boundaries: \n",
        "\n",
        "'IGNORE' for p<0.3\n",
        "\n",
        "'ALERT' for 0.3<=p<0.5\n",
        "\n",
        "'LOCK & ALERT' for p>=0.5"
      ]
    },
    {
      "metadata": {
        "id": "jhSfj59AhfhM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CONTENTS\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Fkm8xU9FkxpM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 1) PACKAGES\n",
        "#   a) Installs\n",
        "#   b) Imports\n",
        "\n",
        "# 2) ENVIRON SET-UP\n",
        "\n",
        "# 3) Q1: ETL to load and store on a local Postgres database\n",
        "\n",
        "# 4) Q2: first transaction was a successful card payment over USD10\n",
        "\n",
        "# 5) Q3: design a system to identify fraudsters\n",
        "# \n",
        "#     a)i) User characteristics for IDing fraudsters\n",
        "#     a)ii) Transaction characteristics for IDing fraudsters\n",
        "#     \n",
        "#     b)i) Combining user & transaction-derived data to create model data\n",
        "#     b)ii) Most predictive features\n",
        "#     b)iii) Data prep\n",
        "#     b)iv) Basic Models\n",
        "#     b)v) Feature Scaling & Selection\n",
        "#     b)vi) Optimised Algorithms\n",
        "#     b)vii) Class Imbalance\n",
        "#     b)viii) Final Model - assess quality\n",
        "#     \n",
        "#     c) Resulting Action & Impact\n",
        "#     \n",
        "#     d) Algorithm - implements the model\n",
        "#     \n",
        "#     Test Algorithm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uzAesX5stqL_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PACKAGES"
      ]
    },
    {
      "metadata": {
        "id": "C5Sz2yscnn4F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Installs"
      ]
    },
    {
      "metadata": {
        "id": "kZkzezqanfoZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install to visualise ROC curve\n",
        "!pip install scikit-plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2eUiNT8Anqay",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "mQmlSdyU4PHd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Basic imports, including ML libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pprint\n",
        "%matplotlib inline\n",
        "\n",
        "# Setting plotting styles\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set_style('white')\n",
        "\n",
        "# Displays all cell's output, not just last output\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "# Sklearn\n",
        "import scikitplot as skplt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler,PolynomialFeatures, Imputer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, recall_score, brier_score_loss, f1_score\n",
        "\n",
        "# Tensorflow & Keras\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c1lPEO8ztvZk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ENVIRON SET-UP\n",
        "\n",
        "**must change path to files** "
      ]
    },
    {
      "metadata": {
        "id": "qdFhppw3IARx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7b69fac3-d2ba-4711-bbed-0a065bcbb006"
      },
      "cell_type": "code",
      "source": [
        "# Add GDrive to Colab environment\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create path for data\n",
        "path = '/content/drive/My Drive/Colab Notebooks/Personal/Revolut/Data/'\n",
        "\n",
        "# View files in folder\n",
        "!ls '/content/drive/My Drive/Colab Notebooks/Personal/Revolut/Data/'"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "countries.csv\t      fx_rates.csv  train_fraudsters.csv    train_users.csv\n",
            "currency_details.csv  README.md     train_transactions.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VtG4oe4xzsKr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract data\n",
        "\n",
        "# All countries ISO information\n",
        "countries_df = pd.read_csv(path+'countries.csv', \n",
        "                           index_col='name')\n",
        "\n",
        "# All currency information\n",
        "currencies_df = pd.read_csv(path+'currency_details.csv',\n",
        "                            index_col='currency')\n",
        "\n",
        "# Hourly FOREX data\n",
        "fx_rates_df = pd.read_csv(path+'fx_rates.csv', \n",
        "                          index_col=0, \n",
        "                          parse_dates=True)\n",
        "fx_rates_df.sort_index(inplace=True)\n",
        "\n",
        "# Array of users who are fraudsters \n",
        "fraudsters_df = pd.read_csv(path+'train_fraudsters.csv', \n",
        "                            index_col=0)\n",
        "fraudsters_df['IS_FRAUDSTER'] = True\n",
        "fraudsters_df = fraudsters_df.set_index('user_id').sort_index()\n",
        "\n",
        "# Characteristics of all users\n",
        "users_df = pd.read_csv(path+'train_users.csv', \n",
        "                       index_col='ID',\n",
        "                       parse_dates=['CREATED_DATE', 'TERMS_VERSION'])\n",
        "\n",
        "# STATE is always 'ACTIVE' for non-fraudsters, 'LOCKED' for fraudsters - therefore remove\n",
        "users_df.drop([users_df.columns[0],'STATE'],\n",
        "              axis=1,\n",
        "              inplace=True)\n",
        "\n",
        "# Data on all transactions\n",
        "transactions_df = pd.read_csv(path+'train_transactions.csv', \n",
        "                              parse_dates=['CREATED_DATE'], \n",
        "                              index_col=['USER_ID','CREATED_DATE']).sort_index()\n",
        "transactions_df.drop(transactions_df.columns[0],\n",
        "                     axis=1,\n",
        "                     inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YN92bFmVQbNi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Q1: ETL to load and store on a local Postgres database\n",
        "\n",
        "**must change path to database**"
      ]
    },
    {
      "metadata": {
        "id": "Lx6voYS5QxDS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Change directory and create .db file\n",
        "\n",
        "!cd '/content/drive/My Drive/Colab Notebooks/Personal/Revolut/Data/'\n",
        "!touch fraudster_postgres.db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "swoPNwoJRrt2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Installs and imports\n",
        "\n",
        "!pip install sqlalchemy\n",
        "!pip install psycopg2\n",
        "\n",
        "import sqlalchemy\n",
        "import sqlalchemy.sql\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "import psycopg2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PHOaQW6DSF1g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Connect to db & define schema\n",
        "\n",
        "# Connect to postgres database\n",
        "engine = create_engine('postgres:///fraudster_postgres.db')\n",
        "\n",
        "# Define schema\n",
        "Base = declarative_base()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ynUs93IeU6ge",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Table structure & defining the schema\n",
        "\n",
        "class transactions(Base):\n",
        "    __tablename__ = \"transactions\"\n",
        "    currency = Column(String)\n",
        "    amount = Column(Integer)\n",
        "    state = Column(String)\n",
        "    created_date = Column(DateTime)\n",
        "    merchant_category = Column(String)\n",
        "    merchant_country = Column(String)\n",
        "    entry_method = Column(String)\n",
        "    user_id = Column(String)\n",
        "    type = Column(String)\n",
        "    source = Column(String)\n",
        "    id = Column(String, primary_key=True)\n",
        "\n",
        "class users(Base):\n",
        "    __tablename__ = \"users\"\n",
        "    id = Column(String, primary_key=True)\n",
        "    has_email = Column(Integer)\n",
        "    phone_country = Column(String)\n",
        "    is_fraudster = Column(Integer)\n",
        "    terms_version = Column(DateTime)\n",
        "    created_date = Column(DateTime)\n",
        "    country = Column(String)\n",
        "    birth_year = Column(Integer)\n",
        "    kyc = Column(String)\n",
        "    failed_sign_in_attempts = Column(Integer)\n",
        "    \n",
        "class fx_rates(Base):\n",
        "    __tablename__ = \"fx_rates\"\n",
        "    ts = Column(DateTime, primary_key=True)\n",
        "    base_ccy = Column(String,primary_key=True)\n",
        "    ccy = Column(String,primary_key=True)\n",
        "    rate = Column(Integer)\n",
        "    \n",
        "class currency_details(Base):\n",
        "    __tablename__ = \"currency_details\"\n",
        "    ccy = Column(String, primary_key=True)\n",
        "    iso_code = Column(Integer)\n",
        "    exponent = Column(Integer)\n",
        "    is_crypto = Column(Integer)\n",
        "\n",
        "    \n",
        "# Create tables\n",
        "transactions.__table__.create(bind=engine, checkfirst=True)\n",
        "users.__table__.create(bind=engine, checkfirst=True)\n",
        "fx_rates.__table__.create(bind=engine, checkfirst=True)\n",
        "currency_details.__table__.create(bind=engine, checkfirst=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kx6bsXH13Zas",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create new Session and commit to database\n",
        "\n",
        "Session = sessionmaker(bind=engine)\n",
        "session = Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CkSzKX1L9ieF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# EXTRACT & TRANSFORM: Make data into suitable form to load\n",
        "\n",
        "# transactions\n",
        "sql_transactions_df = transactions_df.reset_index()\n",
        "sql_transactions_df.columns = [x.lower() for x in sql_transactions_df.columns]\n",
        "\n",
        "# users\n",
        "sql_users_df = pd.concat([users_df,fraudsters_df],axis=1).reset_index()\n",
        "sql_users_df['IS_FRAUDSTER'] = sql_users_df['IS_FRAUDSTER'].fillna(False)\n",
        "sql_users_df.columns = [x.lower() for x in sql_users_df.columns]\n",
        "sql_users_df.rename(columns={'index':'id'},inplace=True)\n",
        "\n",
        "# fx_rates\n",
        "sql_fx_rates_df = pd.DataFrame(fx_rates_df.stack()).reset_index()\n",
        "sql_fx_rates_df['base_ccy'] = sql_fx_rates_df['level_1'].apply(lambda x: x[:3])\n",
        "sql_fx_rates_df['ccy'] = sql_fx_rates_df['level_1'].apply(lambda x: x[3:])\n",
        "sql_fx_rates_df.drop(columns=['level_1'],inplace=True)\n",
        "sql_fx_rates_df.columns = ['ts','rate','base_ccy','ccy']\n",
        "\n",
        "# currency_details\n",
        "sql_currencies_df = currencies_df.reset_index()\n",
        "sql_currencies_df.rename({'currency':'ccy'},inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sftwKqS0xvVp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LOAD: Add data to db via session\n",
        "\n",
        "# transactions\n",
        "for index, row in sql_transactions_df.iterrows():\n",
        "  row = transactions(**row)\n",
        "  session.add(row)\n",
        "\n",
        "# users\n",
        "for index, row in sql_users_df.iterrows():\n",
        "  row = users(**row)\n",
        "  session.add(row)\n",
        "\n",
        "# fx_rates\n",
        "for index, row in sql_fx_rates_df.iterrows():\n",
        "  row = fx_rates(**row)\n",
        "  session.add(row)\n",
        "\n",
        "# currency_details\n",
        "for index, row in sql_currencies_df.iterrows():\n",
        "  row = currency_details(**row)\n",
        "  session.add(row)\n",
        "  \n",
        "# Commit Load session to database\n",
        "session.commit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwoPAkIEiqpm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Q2: first transaction was a successful card payment over USD10"
      ]
    },
    {
      "metadata": {
        "id": "G5ipeLqDqVPr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating long dataframe of just USD-currencies exchange rate at each time period \n",
        "\n",
        "# Dataframe of only USD exchange rates\n",
        "dollar_cols = [x for x in fx_rates_df.columns if x[:3]=='USD']\n",
        "dollar_rates_df = fx_rates_df[dollar_cols].copy()\n",
        "\n",
        "# Make column names the 3 letter ISO code for that currency\n",
        "dollar_rates_df.columns = [x[3:] for x in dollar_rates_df.columns]\n",
        "\n",
        "# Set USD-USD exchange as 1\n",
        "dollar_rates_df['USD'] = 1\n",
        "\n",
        "# Turn from wide to long format\n",
        "stacked_dollars_df = pd.DataFrame(dollar_rates_df.stack()).reset_index()\n",
        "stacked_dollars_df.columns = ['datetime','currency','dollar_exchange']\n",
        "stacked_dollars_df.set_index(['datetime','currency'],inplace=True)\n",
        "\n",
        "# dollar_rates_df.head(2)\n",
        "# stacked_dollars_df.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "MJQKjckIBSQx"
      },
      "cell_type": "code",
      "source": [
        "# Convert transaction amount to dollar value given exchange rate at the relevant time period\n",
        "\n",
        "# Join currency 'exponent' onto transactions\n",
        "transactions_dollar_df = pd.merge(transactions_df, \n",
        "                                  currencies_df, \n",
        "                                  how='left', \n",
        "                                  left_on='CURRENCY', \n",
        "                                  right_index=True)\n",
        "\n",
        "# Join dollar exchange rate  - using the last exchange rate before the transation\n",
        "transactions_dollar_df = pd.merge_asof(transactions_dollar_df.reset_index()\n",
        "                                          .sort_values('CREATED_DATE'),\n",
        "                                       stacked_dollars_df.reset_index(),\n",
        "                                       left_on='CREATED_DATE',\n",
        "                                       right_on='datetime',\n",
        "                                       direction='backward',\n",
        "                                       # Matching to the relevant currency ISO code\n",
        "                                       left_by='CURRENCY',\n",
        "                                       right_by='currency')\n",
        "\n",
        "# Extract exponent and dollar_exchange to create value in dollars of transaction\n",
        "transactions_dollar_df['dollar_amount'] = transactions_dollar_df['AMOUNT'] \\\n",
        "                                            / (10**transactions_dollar_df['exponent']) \\\n",
        "                                            * transactions_dollar_df['dollar_exchange']\n",
        "\n",
        "# Only keep original columns (+'dollar_amount')\n",
        "transactions_dollar_df = transactions_dollar_df\\\n",
        "                            .set_index(transactions_df.index.names)\\\n",
        "                            .sort_index()\\\n",
        "                            [['dollar_amount'] + transactions_df.columns.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5rbO5DQ0qnbu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Answer question by limiting to: \n",
        "# a) first transaction, b) >10USD, c) card payment, d) successful\n",
        "\n",
        "# First transactions of all users\n",
        "first_transactions_dollar_df = transactions_dollar_df.reset_index()\\\n",
        "                                  .groupby('USER_ID')\\\n",
        "                                  .first()\n",
        "\n",
        "# List of users whose first transaction >10USD & was a card payment & was successful\n",
        "users_first_transaction_tenDollars = first_transactions_dollar_df\\\n",
        "                                        [(first_transactions_dollar_df['dollar_amount']>10) \n",
        "                                         & (first_transactions_dollar_df['TYPE']=='CARD_PAYMENT')\\\n",
        "                                         & (first_transactions_dollar_df['STATE']=='COMPLETED')]\\\n",
        "                                        .index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Wm8cbAdLGq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "e2cfb8d1-f986-42db-870a-d90b2a45b65c"
      },
      "cell_type": "code",
      "source": [
        "# Prints the list of those users \n",
        "\n",
        "users_first_transaction_tenDollars"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['07e8e8ea-fc68-4030-89c7-ea79da9e8077',\n",
              "       '09dcf1ba-e33e-4877-867e-173fe9786b6f',\n",
              "       '1b58f732-7d58-460f-bb81-18418b50d325',\n",
              "       '1ee91128-a957-4687-aeb2-e41b7729a08b',\n",
              "       '20a16a2a-ffbf-4e9c-b6fa-9a85c2350647',\n",
              "       '2e04c065-27e2-447b-98c6-7a77437135c8',\n",
              "       '2eb7c137-056b-4a3f-9f98-f2bc4bc2d982',\n",
              "       '3dfa5192-c39f-4b8a-863e-a0b412216897',\n",
              "       '484253ae-3dd7-402e-8565-0b2b612554b3',\n",
              "       '637118fe-c17f-4511-ad4a-54bd3cf02c83',\n",
              "       '65815942-9d63-42d9-a64d-85f8b3bef819',\n",
              "       '84382c07-626d-4220-bdd7-79e0d88aa850',\n",
              "       '99f2b2d4-05f2-4791-981e-ca1bb90c56c8',\n",
              "       'de2e0774-a1e0-47a7-9d9a-bdb992aa3151',\n",
              "       'e18b2729-3b60-4a93-932d-a66551870ea7',\n",
              "       'e3d09774-6184-475e-9401-10c91e2db3d2',\n",
              "       'e8fc10d8-7c74-473a-9957-5a8b45403eda',\n",
              "       'ef051a6c-c0fc-4b29-aea1-2d5c8eec1ade',\n",
              "       'ef628625-caa8-4a9d-ac5c-8163935a711f',\n",
              "       'f23ac151-909f-4bb0-996c-4226c11d894c',\n",
              "       'f4097d7d-012a-4e92-82dc-de4db3fe36d4',\n",
              "       'f63f5c96-2726-4781-8ca4-417c66602e0e'],\n",
              "      dtype='object', name='USER_ID')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "metadata": {
        "id": "D-DOHn_XXkhV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Q3: design a system to identify fraudsters"
      ]
    },
    {
      "metadata": {
        "id": "kH8RbfvTdDK7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3)a)i) User characteristics for IDing fraudsters\n",
        "\n",
        "FAILED_SIGN_IN_ATTEMPTS: more failed attempts = more likely to be a fraudsters\n",
        "\n",
        "KYC: (user verification) - more likely to be a fraudster if failed the verification\n",
        "\n",
        "COUNTRY & PHONE_COUNTRY: Only predictive countries are UK, Lithuania, Romania\n",
        "\n",
        "CREATED_DATE: fraudsters may create their accounts differently than non-fraudsters\n",
        "\n",
        "*   year: fraudsters seem to be less long standing customers (created more recently)\n",
        "*   quarter & month: fraudsters seem more likely to create accounts in Spring (maybe linked to tax year)\n",
        "*   hour: fraudsters seem more likely to create accounts at weird hours (early & later)"
      ]
    },
    {
      "metadata": {
        "id": "ZYlHQWRrXf5f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# users_df.head(2)\n",
        "# fraudsters_df.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u73IXmkUuXYt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Join IS_FRAUDSTER column to user characteristics\n",
        "\n",
        "users_fraud_df = pd.concat([users_df,fraudsters_df],axis=1)\n",
        "users_fraud_df['IS_FRAUDSTER'] = users_fraud_df['IS_FRAUDSTER'].fillna(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T3wiz5ljylzI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "4f51d2fd-7c8e-41b1-af18-d1b59d06d2e2"
      },
      "cell_type": "code",
      "source": [
        "# FAILED_SIGN_IN_ATTEMPTS: more failed attempts = more likely to be a fraudsters\n",
        "\n",
        "users_fraud_df.groupby('FAILED_SIGN_IN_ATTEMPTS')['IS_FRAUDSTER']\\\n",
        "    .agg(['count','mean']).iloc[:3]"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FAILED_SIGN_IN_ATTEMPTS</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10248</td>\n",
              "      <td>0.028981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28</td>\n",
              "      <td>0.035714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         count      mean\n",
              "FAILED_SIGN_IN_ATTEMPTS                 \n",
              "0                        10248  0.028981\n",
              "1                           28  0.035714\n",
              "2                           20  0.100000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "metadata": {
        "id": "XmKAEsATzAfY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "db0d19ff-f9ba-4958-be55-8a168cf97460"
      },
      "cell_type": "code",
      "source": [
        "# KYC: (user verification) - more likely to be a fraudster if failed the verification\n",
        "\n",
        "users_fraud_df.groupby('KYC')['IS_FRAUDSTER'].agg(['count','mean'])"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KYC</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>FAILED</th>\n",
              "      <td>292</td>\n",
              "      <td>0.075342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NONE</th>\n",
              "      <td>2764</td>\n",
              "      <td>0.000362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PASSED</th>\n",
              "      <td>7166</td>\n",
              "      <td>0.036282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PENDING</th>\n",
              "      <td>78</td>\n",
              "      <td>0.217949</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         count      mean\n",
              "KYC                     \n",
              "FAILED     292  0.075342\n",
              "NONE      2764  0.000362\n",
              "PASSED    7166  0.036282\n",
              "PENDING     78  0.217949"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "metadata": {
        "id": "m1xw9N6-udml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "d7a6b69f-34fb-4783-b0e1-5ac989b670df"
      },
      "cell_type": "code",
      "source": [
        "# COUNTRY & PHONE_COUNTRY: Only predictive countries are UK, Lithuania, Romania\n",
        "\n",
        "# Groupby vars to display predictivity\n",
        "users_fraud_df.groupby('COUNTRY')['IS_FRAUDSTER']\\\n",
        "    .agg(['count','sum','mean'])\\\n",
        "    .sort_values('mean',ascending=False)\\\n",
        "    .iloc[:5]\n",
        "users_fraud_df.groupby('PHONE_COUNTRY')['IS_FRAUDSTER']\\\n",
        "    .agg(['count','sum','mean'])\\\n",
        "    .sort_values('mean',ascending=False)\\\n",
        "    .iloc[:6]\n",
        "\n",
        "# Only predictive countries are UK, Lithuania, Romania - set others to 'Other'\n",
        "users_fraud_df.loc[~users_fraud_df['COUNTRY'].isin(['GB','LT','RO']),'COUNTRY'] = 'Other'\n",
        "users_fraud_df.loc[~users_fraud_df['PHONE_COUNTRY'].isin(['GB||JE||IM||GG','LT','RO']),'PHONE_COUNTRY'] = 'Other'"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>sum</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>COUNTRY</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GB</th>\n",
              "      <td>4673</td>\n",
              "      <td>270.0</td>\n",
              "      <td>0.057779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LT</th>\n",
              "      <td>492</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.028455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RO</th>\n",
              "      <td>220</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.018182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BE</th>\n",
              "      <td>91</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CZ</th>\n",
              "      <td>113</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.008850</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         count    sum      mean\n",
              "COUNTRY                        \n",
              "GB        4673  270.0  0.057779\n",
              "LT         492   14.0  0.028455\n",
              "RO         220    4.0  0.018182\n",
              "BE          91    1.0  0.010989\n",
              "CZ         113    1.0  0.008850"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>sum</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PHONE_COUNTRY</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>IN</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>US||PR||CA</th>\n",
              "      <td>29</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.068966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GB||JE||IM||GG</th>\n",
              "      <td>4534</td>\n",
              "      <td>264.0</td>\n",
              "      <td>0.058227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RO</th>\n",
              "      <td>227</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.030837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LT</th>\n",
              "      <td>493</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.028398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CZ</th>\n",
              "      <td>117</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.008547</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                count    sum      mean\n",
              "PHONE_COUNTRY                         \n",
              "IN                  2    1.0  0.500000\n",
              "US||PR||CA         29    2.0  0.068966\n",
              "GB||JE||IM||GG   4534  264.0  0.058227\n",
              "RO                227    7.0  0.030837\n",
              "LT                493   14.0  0.028398\n",
              "CZ                117    1.0  0.008547"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "metadata": {
        "id": "PAt1zd1Luibt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# CREATED_DATE: extract year, quarter, month, hour from datetime account was created\n",
        "# Logic is that fraudsters may create their accounts differently than non-fraudsters\n",
        "# year: fraudsters seem to be less long standing customers (created more recently)\n",
        "# quarter & month: fraudsters seem more likely to create accounts in Spring (maybe linked to tax year)\n",
        "# hour: fraudsters seem more likely to create accounts at weird hours (early & later)\n",
        "\n",
        "# Extract predictive datetime elements from datetime account was created\n",
        "users_fraud_df['CREATED_DATE_year'] = users_fraud_df['CREATED_DATE'].dt.year\n",
        "users_fraud_df['CREATED_DATE_quarter'] = users_fraud_df['CREATED_DATE'].dt.quarter\n",
        "users_fraud_df['CREATED_DATE_month'] = users_fraud_df['CREATED_DATE'].dt.month\n",
        "users_fraud_df['CREATED_DATE_hour'] = users_fraud_df['CREATED_DATE'].dt.hour"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tuHd8N-kdHFn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create dummy variables for categoricals\n",
        "\n",
        "# TERMS_VERSION: filling missing dates\n",
        "users_fraud_df['TERMS_VERSION'].fillna('Missing',inplace=True)\n",
        "\n",
        "# Dummies for categoricals\n",
        "users_fraud_df = pd.get_dummies(users_fraud_df,\n",
        "                                columns=['KYC','COUNTRY','CREATED_DATE_quarter','TERMS_VERSION','PHONE_COUNTRY'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8GEH6lX3dHCW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3)a)ii) Transaction characteristics for IDing fraudsters\n",
        "\n",
        "**Time between account created and first transaction**: fraudsters may immediately conduct transaction after creating account\n",
        "\n",
        "**Transactions per day**: fraudsters likely to have more transactions\n",
        "\n",
        "**Transaction amount**: fraudsters have higher average & thinner distribution\n",
        "\n",
        "**Currencies**: fraudsters use more currencies\n",
        "\n",
        "**Merchants**: fraudsters use fewer merchant categories and use more merchant countries\n",
        "\n",
        "---\n",
        "*Not yet done*:\n",
        "1.   **variance of times between transactions** = fraudsters have lower variance\n",
        "2.   **variance of hours of transactions** = fraudsters use more extreme hours\n",
        "3.   whether they **use currencies not affiliated with, or spend in merchant countries which aren't, the user's registered country**: fraudsters use abnormal currencies in abnormal countries "
      ]
    },
    {
      "metadata": {
        "id": "ZpVQSxDxdOSo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# transactions_dollar_df.head(2)\n",
        "# transactions_dollar_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bmhjaewp5QoP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Per user, extract first & last transactions, and total number of transactions\n",
        "\n",
        "# Hypothesise that these are predictive:\n",
        "# a) Time between account created and first transaction: fraudsters may immediately conduct transaction after creating account\n",
        "# b) Transactions per day: fraudsters likely to have more transactions\n",
        "\n",
        "# first & last transaction dates\n",
        "firstlast_transcation_date_df = transactions_dollar_df.reset_index().groupby('USER_ID')['CREATED_DATE'].agg(['first','last'])\n",
        "firstlast_transcation_date_df.columns = ['transaction_'+x for x in firstlast_transcation_date_df.columns]\n",
        "\n",
        "# num_transactions\n",
        "num_transactions_df = pd.DataFrame(transactions_dollar_df.groupby('USER_ID').size(),columns=['num_transactions'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e8opBa8i6RVw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Per user, extract mean, median, std of dollar amount of transactions\n",
        "\n",
        "# Hypothesise that:\n",
        "# a) Fraudsters have higher average\n",
        "# b) Fraudsters have lesser distribution\n",
        "\n",
        "dollar_amounts_df = transactions_dollar_df.groupby('USER_ID')['dollar_amount'].agg(['mean','median','std'])\n",
        "dollar_amounts_df.columns = ['dollar_amount_'+x for x in dollar_amounts_df.columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DRc9kb8x6sa3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Per user, calculate number of different: \n",
        "# - CURRENCY: hypothesise that fraudsters use more currencies\n",
        "# - MERCHANT_CATEGORY: hypothesise that fraudsters use fewer merchant categories\n",
        "# - MERCHANT_COUNTRY: hypothesise that fraudsters use more merchant countries\n",
        "\n",
        "# Number of currencies used\n",
        "num_currencies_df = transactions_dollar_df.groupby('USER_ID')[['CURRENCY']].nunique()\n",
        "num_currencies_df.columns = ['CURRENCY_nunique']\n",
        "\n",
        "\n",
        "# Fill missing merchant data\n",
        "transactions_dollar_df.fillna('Missing',inplace=True)\n",
        "\n",
        "# Number of merchant categories\n",
        "merchant_category_df = pd.DataFrame(data={\n",
        "    'merchant_category_missing':transactions_dollar_df[transactions_dollar_df['MERCHANT_CATEGORY']=='Missing'].groupby('USER_ID').size(),\n",
        "    'merchant_category_nunique':transactions_dollar_df.groupby('USER_ID')['MERCHANT_CATEGORY'].nunique()\n",
        "})\n",
        "\n",
        "# Number of merchant countries\n",
        "merchant_country_df = pd.DataFrame(data={\n",
        "    'merchant_country_missing':transactions_dollar_df[transactions_dollar_df['MERCHANT_COUNTRY']=='Missing'].groupby('USER_ID').size(),\n",
        "    'merchant_country_nunique':transactions_dollar_df.groupby('USER_ID')['MERCHANT_COUNTRY'].nunique()\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "72qFSALA70qo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Per user, sum categories for:\n",
        "# - STATE: fraudster transactions more likely to fail\n",
        "# - ENTRY_METHOD: fraudsters have different dispersion\n",
        "# - TYPE: fraudsters have different dispersion\n",
        "# - SOURCE: fraudsters have different dispersion\n",
        "\n",
        "# STATE\n",
        "states_df = transactions_dollar_df.groupby(['USER_ID','STATE']).size().unstack().fillna(0)\n",
        "states_df.columns = ['STATE_'+x for x in states_df.columns]\n",
        "\n",
        "# ENTRY_METHOD\n",
        "entry_method_df = transactions_dollar_df.groupby(['USER_ID','ENTRY_METHOD']).size().unstack().fillna(0)\n",
        "entry_method_df.columns = ['ENTRY_METHOD_'+x for x in entry_method_df.columns]\n",
        "\n",
        "# TYPE\n",
        "type_df = transactions_dollar_df.groupby(['USER_ID','TYPE']).size().unstack().fillna(0)\n",
        "type_df.columns = ['TYPE_'+x for x in type_df.columns]\n",
        "\n",
        "# SOURCE\n",
        "source_df = transactions_dollar_df.groupby(['USER_ID','SOURCE']).size().unstack().fillna(0)\n",
        "source_df.columns = ['SOURCE_'+x for x in source_df.columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9jSVaBnf-Zm5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3)b)i) Combining user & transaction-derived data to create model data"
      ]
    },
    {
      "metadata": {
        "id": "iJXo2aPx-dsQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Combine all transaction-derived data into user-level modelling data\n",
        "\n",
        "model_df = pd.concat([users_fraud_df,\n",
        "                      firstlast_transcation_date_df,\n",
        "                      num_transactions_df,\n",
        "                      dollar_amounts_df,\n",
        "                      num_currencies_df,\n",
        "                      states_df,\n",
        "                      merchant_category_df,\n",
        "                      merchant_country_df,\n",
        "                      entry_method_df,\n",
        "                      type_df,\n",
        "                      source_df],\n",
        "                     axis=1)\n",
        "\n",
        "# model_df.head(2)\n",
        "# model_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6oUEXWcu98WE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create bool feature if transaction data missing \n",
        "# (only 8021 out of 10300 users have transaction data)\n",
        "\n",
        "model_df['transactions_missing'] = model_df['num_transactions'].isnull()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pQfC4nve7GGg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Date derived variables\n",
        "\n",
        "# Hypothesise that these are predictive:\n",
        "# a) Time between account created and first transaction: fraudsters may immediately conduct transaction after creating account\n",
        "# b) Transactions per day: fraudsters likely to have more transactions\n",
        "\n",
        "# model_df[['CREATED_DATE','transaction_first','transaction_last']].head()\n",
        "\n",
        "# How many seconds after account created happens the first transaction\n",
        "model_df['time_to_first_transaction'] = (model_df['transaction_first'] - model_df['CREATED_DATE']).dt.seconds\n",
        "\n",
        "# transactions per day\n",
        "model_df['transactions_per_day'] = model_df['num_transactions'] / (model_df['transaction_last'] - model_df['transaction_first']).dt.seconds * 60.0 * 60 * 24\n",
        "model_df['transactions_per_day'].replace([np.inf, -np.inf], 0, inplace=True)\n",
        "\n",
        "model_df.drop(columns=['CREATED_DATE','transaction_first','transaction_last'],\n",
        "              inplace=True,\n",
        "              errors='ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4dRQj9_u_KoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Separation of target and data\n",
        "\n",
        "y_target = model_df['IS_FRAUDSTER']\n",
        "X_data = model_df.drop(columns=['IS_FRAUDSTER'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G55CKVB1PEwY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3)b)ii) Most predictive features\n",
        "\n",
        "- SOURCE_MINOS: if many transactions came through MINOS, much more likely to be a fraudster\n",
        "- dollar_amount_mean: higher transaction amounts = more likely to be fraudster\n",
        "- dollar_amount_std: higher transaction variation = more likely to be fraudster\n",
        "- CURRENCY_nunique: more currencies used = **less** likely to be fraudster\n",
        "- dollar_amount_median: transaction values are very predictive.."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "VQtxhW5BCghd"
      },
      "cell_type": "code",
      "source": [
        "# Run quick RandomForest to get most predictive features\n",
        "\n",
        "# Use out-of-box RandomForest for feature importances\n",
        "rfc = RandomForestClassifier();\n",
        "rfc.fit(Imputer(strategy='median').fit_transform(X_data), y_target);\n",
        "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
        "                                   index = X_data.columns,\n",
        "                                   columns=['importance'])\\\n",
        "                          .sort_values('importance',ascending=False);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3zEkut2BCdUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "b9896299-7bed-4843-d4bc-8be715627fd3"
      },
      "cell_type": "code",
      "source": [
        "# 5 most important features\n",
        "\n",
        "feature_importances.head(5)\n",
        "model_df.groupby('IS_FRAUDSTER')[feature_importances.head(5).index].mean()"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SOURCE_MINOS</th>\n",
              "      <td>0.152422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dollar_amount_std</th>\n",
              "      <td>0.067385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dollar_amount_median</th>\n",
              "      <td>0.063248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dollar_amount_mean</th>\n",
              "      <td>0.040490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>merchant_country_nunique</th>\n",
              "      <td>0.039376</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          importance\n",
              "SOURCE_MINOS                0.152422\n",
              "dollar_amount_std           0.067385\n",
              "dollar_amount_median        0.063248\n",
              "dollar_amount_mean          0.040490\n",
              "merchant_country_nunique    0.039376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SOURCE_MINOS</th>\n",
              "      <th>dollar_amount_std</th>\n",
              "      <th>dollar_amount_median</th>\n",
              "      <th>dollar_amount_mean</th>\n",
              "      <th>merchant_country_nunique</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IS_FRAUDSTER</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>1.054779</td>\n",
              "      <td>199.997631</td>\n",
              "      <td>49.414176</td>\n",
              "      <td>108.705409</td>\n",
              "      <td>4.340067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>9.735786</td>\n",
              "      <td>840.565322</td>\n",
              "      <td>239.840022</td>\n",
              "      <td>513.427722</td>\n",
              "      <td>2.508361</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              SOURCE_MINOS  dollar_amount_std  dollar_amount_median  \\\n",
              "IS_FRAUDSTER                                                          \n",
              "False             1.054779         199.997631             49.414176   \n",
              "True              9.735786         840.565322            239.840022   \n",
              "\n",
              "              dollar_amount_mean  merchant_country_nunique  \n",
              "IS_FRAUDSTER                                                \n",
              "False                 108.705409                  4.340067  \n",
              "True                  513.427722                  2.508361  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "metadata": {
        "id": "3d7iLI7IAp0H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3)b)iii) Data prep"
      ]
    },
    {
      "metadata": {
        "id": "QP0KBlIsAr5X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train-Test Split"
      ]
    },
    {
      "metadata": {
        "id": "PEKtCJ1jAyuB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split data into Train-Val-Test (60-20-20)\n",
        "\n",
        "# train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, \n",
        "                                                    y_target, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=42,\n",
        "                                                    stratify=y_target)\n",
        "\n",
        "# withold 25% of training set for validation of hyperparameters\n",
        "validation_threshold = round(len(X_train)*3/4)\n",
        "X_val = X_train.iloc[validation_threshold:]\n",
        "y_val = y_train[validation_threshold:]\n",
        "\n",
        "# make X_train & y_train exclude validation data\n",
        "X_train = X_train.iloc[:validation_threshold]\n",
        "y_train = y_train[:validation_threshold]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "URuJAYtBBxcM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Impution"
      ]
    },
    {
      "metadata": {
        "id": "gz6JJeVPBnuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fill missing values with medians\n",
        "\n",
        "imputation = Imputer(strategy='median')\n",
        "\n",
        "X_train = imputation.fit_transform(X_train)\n",
        "X_val = imputation.transform(X_val)\n",
        "X_test = imputation.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Ldmb_NfFX6Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3)b)iv) Basic Models\n",
        "\n",
        "For a baseline"
      ]
    },
    {
      "metadata": {
        "id": "qwfcgPknFXG1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LogReg out-of-the-box to get a baseline - plot ROCs for training & test\n",
        "\n",
        "# # no optimisation, just to see basic accuracy\n",
        "# logreg = LogisticRegression(random_state=42)\n",
        "# logreg.fit(X_train,y_train)\n",
        "\n",
        "# probs_train = logreg.predict_proba(X_train)\n",
        "# probs_test = logreg.predict_proba(X_test)\n",
        "\n",
        "# print('\\n')\n",
        "# print('Basic logreg training roc_auc_score:', roc_auc_score(y_train,probs_train[:,1]))\n",
        "# print('Basic logreg training Brier loss score:', brier_score_loss(y_train,probs_train[:,1]))\n",
        "# print('Basic logreg test roc_auc_score:', roc_auc_score(y_test,probs_test[:,1]))\n",
        "# print('Basic logreg test Brier loss score:', brier_score_loss(y_test,probs_test[:,1]),'\\n')\n",
        "\n",
        "# # Plot ROCs for Train & Test\n",
        "# skplt.metrics.plot_roc(y_train,probs_train, title='LogReg Train ROC');\n",
        "# skplt.metrics.plot_roc(y_test,probs_test, title='LogReg Test ROC');\n",
        "\n",
        "# print('\\n \\n', 'Confusion matrix for train')\n",
        "# confusion_matrix(y_train,logreg.predict(X_train))\n",
        "# print('\\n')\n",
        "# print('Confusion matrix for test')\n",
        "# confusion_matrix(y_test,logreg.predict(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qI0105S6MO9G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# RandomForest out-of-the-box to get a baseline - plot ROCs for training & test\n",
        "\n",
        "# # no optimisation, just to see basic accuracy\n",
        "# forest = RandomForestClassifier(random_state=42,\n",
        "#                                 n_estimators=100,\n",
        "#                                 max_depth=10)\n",
        "# forest.fit(X_train,y_train)\n",
        "\n",
        "# probs_train = forest.predict_proba(X_train)\n",
        "# probs_test = forest.predict_proba(X_test)\n",
        "\n",
        "# print('\\n','Basic RandomForest training roc_auc_score:', roc_auc_score(y_train,probs_train[:,1]))\n",
        "# print('Basic RandomForest training Brier loss score:', brier_score_loss(y_train,probs_train[:,1]))\n",
        "# print('Basic RandomForest test roc_auc_score:', roc_auc_score(y_test,probs_test[:,1]))\n",
        "# print('Basic RandomForest test Brier loss score:', brier_score_loss(y_test,probs_test[:,1]),'\\n')\n",
        "\n",
        "# # Plot ROCs for Train & Test\n",
        "# skplt.metrics.plot_roc(y_train,probs_train, title='RandomForest Train ROC');\n",
        "# skplt.metrics.plot_roc(y_test,probs_test, title='RandomForest Test ROC');\n",
        "\n",
        "# print('\\n \\n', 'Confusion matrix for train')\n",
        "# confusion_matrix(y_train,forest.predict(X_train))\n",
        "# print('\\n')\n",
        "# print('Confusion matrix for test')\n",
        "# confusion_matrix(y_test,forest.predict(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Evj1RxCQN3Gm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3)b)v) Feature Scaling & Selection"
      ]
    },
    {
      "metadata": {
        "id": "Q0u3KD9DN74o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create pipeline for Feature Scaling & Selection:\n",
        "# First scale features,\n",
        "# then create interactions to poly=3, \n",
        "# then use PCA to reduce to 50 features\n",
        "\n",
        "features_pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('polyFeat', PolynomialFeatures(degree=2, \n",
        "                                    include_bias=False)),\n",
        "    ('pca', PCA(n_components=50, \n",
        "                random_state=42))\n",
        "])\n",
        "\n",
        "# Fit then transform Train-Val-Test data\n",
        "X_train = features_pipe.fit_transform(X_train)\n",
        "X_val = features_pipe.transform(X_val)\n",
        "X_test = features_pipe.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zljieTWoDqwB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3)b)vi) Optimised Algorithms"
      ]
    },
    {
      "metadata": {
        "id": "C6cI3MT0T73w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbors"
      ]
    },
    {
      "metadata": {
        "id": "2eW3FKYfT9pl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for KNN\n",
        "\n",
        "# Implementation takes a few minutes, so commented out to avoid accidentally running.\n",
        "\n",
        "# neighbors_params = [1,2,4,7,11,16,22,29,37,46,56,67]\n",
        "# knn_train_scores = []\n",
        "# knn_val_scores = []\n",
        "\n",
        "# for k in neighbors_params:\n",
        "#   knn = KNeighborsClassifier(n_neighbors=k)\n",
        "#   knn.fit(X_train,y_train)\n",
        "  \n",
        "#   probs_train = knn.predict_proba(X_train)\n",
        "#   probs_val = knn.predict_proba(X_val)\n",
        "  \n",
        "#   knn_train_scores.append(brier_score_loss(y_train,probs_train[:,1]))\n",
        "#   knn_val_scores.append(brier_score_loss(y_val,probs_val[:,1]))\n",
        "\n",
        "\n",
        "# # Plot Train & Val scores for different K in KNN\n",
        "# knn_scores_df = pd.DataFrame(data={'train':knn_train_scores,\n",
        "#                                    'val':knn_val_scores},\n",
        "#                              index=neighbors_params)\n",
        "# knn_scores_df.plot(title='KNN brier_score_loss for different k');\n",
        "# plt.xlabel('#neighbors');\n",
        "# plt.ylabel('brier_score_loss');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8lPlSnhZahT_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ]
    },
    {
      "metadata": {
        "id": "FzUjQ31zaj-7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for Random Forest, using the two key hyperparameters:\n",
        "# i) Number of estimators: how many trees in forest\n",
        "# ii) Maximum depth: maximum layers of nodes\n",
        "\n",
        "# Implementation takes a few minutes, so commented out to avoid accidentally running.\n",
        "\n",
        "# tree_estimators_params = [int(round(n)) for n in np.logspace(0,3,num=4)]\n",
        "# tree_depth_params = [int(round(depth)) for depth in np.logspace(0.5,2,num=4)]\n",
        "# tree_scores_df = pd.DataFrame(columns=['n_estimators',\n",
        "#                                        'max_depth',\n",
        "#                                        'train_score',\n",
        "#                                        'val_score'])\n",
        "\n",
        "# for n in tree_estimators_params:\n",
        "#   for depth in tree_depth_params:\n",
        "#     forest = RandomForestClassifier(random_state=42,\n",
        "#                                     n_estimators=n,\n",
        "#                                     max_depth=depth)\n",
        "#     forest.fit(X_train,y_train)\n",
        "\n",
        "#     probs_train = forest.predict_proba(X_train)\n",
        "#     probs_val = forest.predict_proba(X_val)\n",
        "    \n",
        "#     tree_scores_df = tree_scores_df.append(\n",
        "#       {'n_estimators':n,\n",
        "#        'max_depth':depth,\n",
        "#        'train_score':brier_score_loss(y_train,probs_train[:,1]),\n",
        "#        'val_score':brier_score_loss(y_val,probs_val[:,1])\n",
        "#       },\n",
        "#       ignore_index=True\n",
        "#     )\n",
        "\n",
        "\n",
        "# # Create heatmap of n_estimators vs max_depth, with heat=validation_score\n",
        "# sns.heatmap(tree_scores_df.pivot_table(values='val_score',index='n_estimators',columns='max_depth'),\n",
        "#             annot=True);\n",
        "# plt.title('Validation score for two key hyperparams \\n for Random Forest');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "77cx3Z_WUkou",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3)b)vii) Class Imbalance"
      ]
    },
    {
      "metadata": {
        "id": "w7bKMv9KUlxu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Only ~3% of customers are fraudsters - therefore problem of class imbalance.\n",
        "# Recall is low. This means that of those who are actually fraudsters, few are predicted to be so.\n",
        "# Therefore, I try rebalancing the classes.\n",
        "\n",
        "# tree_weighting_params = [None,'balanced','balanced_subsample']\n",
        "# tree_weighting_scores_df = pd.DataFrame(columns=['weighting',\n",
        "#                                                  'train_score',\n",
        "#                                                  'val_score',\n",
        "#                                                  'val_recall'])\n",
        "\n",
        "# for weight in tree_weighting_params:\n",
        "#   forest = RandomForestClassifier(random_state=42,\n",
        "#                                   n_estimators=100,\n",
        "#                                   max_depth=32,\n",
        "#                                   class_weight=weight)\n",
        "#   forest.fit(X_train,y_train)\n",
        "\n",
        "#   probs_train = forest.predict_proba(X_train)\n",
        "#   probs_val = forest.predict_proba(X_val)\n",
        "\n",
        "#   tree_weighting_scores_df = tree_weighting_scores_df.append(\n",
        "#     {'weighting':weight,\n",
        "#      'train_score':brier_score_loss(y_train,probs_train[:,1]),\n",
        "#      'val_score':brier_score_loss(y_val,probs_val[:,1]),\n",
        "#      'val_recall':recall_score(y_val,forest.predict(X_val))\n",
        "#     },\n",
        "#     ignore_index=True\n",
        "#   )\n",
        "  \n",
        "\n",
        "# # Show scores for different weightings\n",
        "# tree_weighting_scores_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e5Bkkj3JdlhI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3)b)viii) Final Model - assess quality\n",
        "\n",
        "Use a RandomForest with optimised hyperparameters.\n",
        "\n",
        "Slight overfitting but not too bad.\n",
        "\n",
        "Brier Score is very low for the test set (<2%) - this means overall the model produces a good probabilistic prediction.\n",
        "\n",
        "The **unbalanced classes** remain a concern:\n",
        "- My *Precision* is excellent (>0.9): of those which I predict as fraudsters, almost all are in fact fraudsters\n",
        "- My *Recall* is poor (<0.4): of those who are fraudsters, I predict less than half as fraudsters\n",
        "- Further work needs to explicitly optimise this trade-off "
      ]
    },
    {
      "metadata": {
        "id": "d2Ic8juedndb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "9c880aac-0eb5-417d-b8ca-b23aba27c7d7"
      },
      "cell_type": "code",
      "source": [
        "# Use optimal hyperparameters to fit model, extracting final auc_score on Test data.\n",
        "\n",
        "forest = RandomForestClassifier(random_state=42,\n",
        "                                n_estimators=100,\n",
        "                                max_depth=32,\n",
        "                                class_weight=None)\n",
        "\n",
        "forest.fit(X_train,y_train);\n",
        "probs_train = forest.predict_proba(X_train)\n",
        "probs_test = forest.predict_proba(X_test)\n",
        "\n",
        "print('\\n')\n",
        "print('\\n', 'Final train roc_auc_score:', roc_auc_score(y_train,probs_train[:,1]))\n",
        "print('\\n', 'Final test roc_auc_score:', roc_auc_score(y_test,probs_test[:,1]))\n",
        "print('\\n', 'Final train Brier score:', brier_score_loss(y_train,probs_train[:,1]))\n",
        "print('\\n', 'Final test Brier score:', brier_score_loss(y_test,probs_test[:,1]))\n",
        "\n",
        "print('\\n', 'Confusion matrix for train')\n",
        "confusion_matrix(y_train,forest.predict(X_train))\n",
        "print('\\n')\n",
        "print('Confusion matrix for test')\n",
        "confusion_matrix(y_test,forest.predict(X_test))"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=32, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
              "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " Final train roc_auc_score: 1.0\n",
            "\n",
            " Final test roc_auc_score: 0.9456541666666666\n",
            "\n",
            " Final train Brier score: 0.0023365857605177993\n",
            "\n",
            " Final test Brier score: 0.017293252427184467\n",
            "\n",
            " Confusion matrix for train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6010,    0],\n",
              "       [   0,  170]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Confusion matrix for test\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1999,    1],\n",
              "       [  42,   18]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "metadata": {
        "id": "mTwbhBI7Hf1_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3)c) Resulting Action & Impact\n",
        "\n",
        "Use probabilities from model to predict chance of fraudster.\n",
        "\n",
        "The trade off is between annoying False Positives (locking someone's account unnecssarily, frustrating for customer) and important False Negatives (missing fraudsters, worrisome for Revolut's regulatory compliance).\n",
        "\n",
        "The resulting action takes this structure:\n",
        "- If prob <0.3: 'IGNORE' - even though this includes some fraudsters\n",
        "- If prob >=0.3 & <0.5: 'ALERT' - higher chance of fraudster but still much uncertainty\n",
        "- If prob >=0.5: 'LOCK & ALERT' - almost definitely a fraudster\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Gh6dJ655fi4w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualise probabilities vs target label to see if clear separation\n",
        "\n",
        "plt.scatter(probs_train[:,1],y_train);\n",
        "plt.title('Train model probabilities vs actual target labels');\n",
        "plt.xlabel('Model probability predict');\n",
        "plt.ylabel('Actual target label');\n",
        "\n",
        "plt.figure();\n",
        "\n",
        "plt.scatter(probs_test[:,1],y_test);\n",
        "plt.title('Test model probabilities vs actual target labels');\n",
        "plt.xlabel('Model probability predict');\n",
        "plt.ylabel('Actual target label');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UZeCp-1igXLP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Q3)d) Algorithm - implements the model "
      ]
    },
    {
      "metadata": {
        "id": "U_6hRGQlipnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "519e65d7-a398-4c5a-e494-68147edef34e"
      },
      "cell_type": "code",
      "source": [
        "def fraudster_action(user_id,\n",
        "                     prepped_model_data=model_df):\n",
        "  \n",
        "  user_info = prepped_model_data.loc[user_id]\n",
        "\n",
        "  user_target = user_info['IS_FRAUDSTER']\n",
        "  user_data = user_info.drop(index='IS_FRAUDSTER')\n",
        "\n",
        "  X_user = imputation.transform(user_data.values.reshape(1, -1))\n",
        "  X_user = features_pipe.transform(X_user)\n",
        "\n",
        "  user_pred = forest.predict(X_user)\n",
        "  user_prob = forest.predict_proba(X_user)[0][1]\n",
        "  \n",
        "  if user_prob < 0.3:\n",
        "    return 'IGNORE'\n",
        "  elif user_prob >= 0.3 and user_prob < 0.5:\n",
        "    return 'ALERT'\n",
        "  elif user_prob > 0.5:\n",
        "    return 'LOCK & ALERT'\n",
        "  \n",
        "\n",
        "# Example\n",
        "fraudster_action(user_id='b2fc491b-1bf1-409b-be49-770881e3476e',\n",
        "                 prepped_model_data=model_df)"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'IGNORE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "metadata": {
        "id": "tL6jdlLbKCTK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test Algorithm"
      ]
    },
    {
      "metadata": {
        "id": "WhyEnTpoKJDY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fraudster_action(user_id='...',\n",
        "#                  prepped_model_data=model_df)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}