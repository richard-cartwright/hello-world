{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_data_requirements.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "H9Y21oWVgs6V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# What this script does: Creates gantt charts which match data in the database with project requirements.\n",
        "\n",
        "# 1) Retrieves list of Tables & sizes from the database\n",
        "# 2) Reads in list of Projects & their data requirements\n",
        "# 3) Separates tables into monthly and daily timeframes\n",
        "# 4) Creates (long) gantt charts for of the two inputs (i.Tables; ii.Projects), for each timeframe\n",
        "# 5) Combine the gantt chart from each input into an overall gantt, for each timeframe\n",
        "\n",
        "# 6) This overall gantt includes all tables as columns, and all dates as the index.\n",
        "# >> The values in each cell represent what should be done to the table in the database:\n",
        "# a) 'Null' = if not in Tables, not needed in Projects\n",
        "# b) 'Drop' = if in Tables, not needed in Projects\n",
        "# c) 'Add' = if not in Tables, needed in Projects (including the project names that require this data)\n",
        "# d) 'Keep' = if in Tables, needed in Projects (including the project names that require this data)\n",
        "\n",
        "# 7) Adjust output of overall gantts to take into account Jira tickets\n",
        "# 8) Dataframe of how much space is taken up by the tables associated with each project\n",
        "\n",
        "# 9) Creates dataframe, from Tables input, of how much space each schema takes up in the database\n",
        "# 10) Export as a csv the two size tables, the two overall gantts, and the one space dataframe\n",
        "\n",
        "\n",
        "# NB: in order to preserve IP, I have replaced any database information with '***'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UYAiqW2sbWzV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# IMPORTANT\n",
        "# 1) spreadsheet link\n",
        "# 2) postgres credentials\n",
        "# 3) link on your computer to the Git postgres_to_redshift_scripts folder to extract the generic script \n",
        "\n",
        "# 1) This is the hub spreadsheet. Change this and everything is golden.\n",
        "spreadsheet_link = '...'\n",
        "\n",
        "# 2)a) Set these postgres credentials\n",
        "pg_username = '...'\n",
        "pg_host = '...'\n",
        "pg_port = '...'\n",
        "pg_database = '...'\n",
        "\n",
        "# 2)b) Extract your postgres password - ideally using keyring from Windows Credentials\n",
        "import keyring\n",
        "pg_password = keyring.get_password(pg_database, pg_username)\n",
        "\n",
        "# 3) link on your computer to the Git postgres_to_redshift_scripts folder to extract the generic script \n",
        "import sys\n",
        "sys.path.append(r'...')\n",
        "from databaseFunctions import getTableFromDatabase"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bzFuwb1kblt4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Basic imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# Setting plotting styles\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set_style('white')\n",
        "\n",
        "# Displays all cell's output, not just last output\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "# For interacting with a spreadsheet\n",
        "import xlrd\n",
        "import xlwt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PLuPXVtOkiei",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 1) Retrieves list of Tables & sizes from the database\n",
        "\n",
        "# Retrieve data from database using generic function in postgres_to_redshift_scripts\n",
        "stmt = \"\"\"\n",
        "...\n",
        ";\n",
        "\"\"\"\n",
        "all_tables_df = getTableFromDatabase( username = pg_username,\n",
        "                                      password = pg_password,\n",
        "                                      host = pg_host,\n",
        "                                      port = pg_port,\n",
        "                                      database = pg_database,\n",
        "                                      stmt = stmt)\n",
        "\n",
        "# Select only *** schema\n",
        "tables_df = all_tables_df[all_tables_df.schemaname == '***'].drop('***', axis=1).copy()\n",
        "\n",
        "# Categorise as monthly or daily - based on the suffix of YYYYmm or YYYYmmdd\n",
        "tables_df['timeframe'] = tables_df.relname.apply(lambda x: 'monthly' if len(x.split('_')[-1])==6\\\n",
        "                                                            else 'daily')\n",
        "\n",
        "# Extract & parse date\n",
        "tables_df['date'] = tables_df.relname.apply(\n",
        "    lambda x: pd.to_datetime(x.split('_')[-1], format='%Y%m') if len(x.split('_')[-1]) == 6 \\\n",
        "    else pd.to_datetime(x.split('_')[-1], format='%Y%m%d'))\n",
        "\n",
        "# Extract pure table name\n",
        "tables_df['table'] = tables_df.relname.apply(lambda x: '_'.join(x.split('_')[:-1]))\n",
        "\n",
        "# Extract size measurement & unit\n",
        "tables_df['size_num'] = tables_df.size.apply(\n",
        "    lambda x: int(x.split(' ')[0]))\n",
        "tables_df['size_unit'] = tables_df.size.apply(\n",
        "    lambda x: x.split(' ')[-1])\n",
        "\n",
        "# Function to create standardised size in MBs\n",
        "def into_MBs(row):\n",
        "    if row['size_unit']=='MB':\n",
        "      return row['size_num']\n",
        "    elif row['size_unit']=='GB':\n",
        "      return row['size_num']*1000\n",
        "    elif row['size_unit']=='kB':\n",
        "      return row['size_num']/1000\n",
        "    elif row['size_unit']=='bytes':\n",
        "      return row['size_num']/10**6\n",
        "\n",
        "tables_df['size_MBs'] = tables_df.apply(lambda row: into_MBs(row), axis=1)\n",
        "\n",
        "# Set Index & drop uneccessary columns\n",
        "tables_df = tables_df.set_index(['table', 'timeframe', 'date']).drop(['size', 'size_num', 'size_unit'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rBpiOMsY6uX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 2) Reads in list of Projects & their data requirements\n",
        "\n",
        "# Read in Projects data\n",
        "HUB_projects_df = pd.read_excel(spreadsheet_link, \n",
        "                                sheet_name='***', \n",
        "                                header=3)\n",
        "HUB_projects_df.head(2)\n",
        "\n",
        "# Select only relevant tables, and if the table still needed\n",
        "HUB_projects_df = HUB_projects_df[(HUB_projects_df.Database == '***') & \n",
        "                                 (HUB_projects_df['Data Removed'] != 'Y')]\n",
        "\n",
        "# Select only relevant columns, and rename\n",
        "projects_csv_df = HUB_projects_df[['Project Name', 'Data Table', 'Data Start', 'Data End']].copy()\n",
        "projects_csv_df.columns = ['project', 'table', 'start', 'end']\n",
        "\n",
        "# Lowercase table name as standard\n",
        "projects_csv_df['table'] = projects_csv_df.table.apply(lambda x: x.lower())\n",
        "\n",
        "# Date columns into datetime format\n",
        "projects_csv_df['start'] = pd.to_datetime(projects_csv_df['start'], infer_datetime_format=True)\n",
        "projects_csv_df['end'] = pd.to_datetime(projects_csv_df['end'], infer_datetime_format=True)\n",
        "\n",
        "# Set index to format nicely\n",
        "projects_csv_df = projects_csv_df.set_index(['project', 'table'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W585fj8boiH1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Checking Tables & Projects dfs\n",
        "\n",
        "tables_df.head(2)\n",
        "projects_csv_df.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UDUde4Hf0i_t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 3) Separates tables into monthly and daily timeframes\n",
        "# 4)a) Creates (long) gantt charts for Projects, for each timeframe\n",
        "\n",
        "# Select just monthly tables, then pivot to produce a Gantt\n",
        "monthly_tables_gantt = tables_df.loc[(slice(None), 'monthly', slice(None)), :]\\\n",
        "                        .reset_index()\\\n",
        "                        .pivot(index='date', columns='table', values='size_MBs')\n",
        "# Displaying monthly dates as months not first days\n",
        "monthly_tables_gantt.index = monthly_tables_gantt.index.to_period('M')\n",
        "\n",
        "# Select just daily tables, then pivot to produce a Gantt\n",
        "daily_tables_gantt = tables_df.loc[(slice(None), 'daily', slice(None)), :]\\\n",
        "                        .reset_index()\\\n",
        "                        .pivot(index='date', columns='table', values='size_MBs')\n",
        "\n",
        "# Complete list of tables which should be represented in database\n",
        "# Doesn't need to be alphabetical because sorted later\n",
        "fulllist_monthly_tables = ['***']\n",
        "fulllist_daily_tables = ['***']\n",
        "\n",
        "# Add any columns which should be represented in database, but contain no data (so don't appear)\n",
        "for col in fulllist_monthly_tables:\n",
        "    if col not in monthly_tables_gantt.columns:\n",
        "        monthly_tables_gantt[col] = np.nan\n",
        "for col in fulllist_daily_tables:\n",
        "    if col not in daily_tables_gantt.columns:\n",
        "        daily_tables_gantt[col] = np.nan\n",
        "\n",
        "# Order columns alphabetically\n",
        "monthly_tables_gantt = monthly_tables_gantt[sorted(monthly_tables_gantt.columns)]\n",
        "daily_tables_gantt = daily_tables_gantt[sorted(daily_tables_gantt.columns)]\n",
        "\n",
        "# Remove any sizes which are smaller than 0.1MB as these tables do not really contain data,\n",
        "# but may have leftover tiny size as a legacy of previous data stored in them\n",
        "monthly_tables_gantt = monthly_tables_gantt.where((monthly_tables_gantt > 0.1) \\\n",
        "                                                  & (monthly_tables_gantt is not None))\n",
        "daily_tables_gantt = daily_tables_gantt.where((daily_tables_gantt > 0.1) \\\n",
        "                                                  & (daily_tables_gantt is not None))\n",
        "\n",
        "# Checking results\n",
        "monthly_tables_gantt.head(2)\n",
        "daily_tables_gantt.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QIOkb7pTlLyY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 4)b) Creates (long) gantt charts for Projects, for each timeframe\n",
        "\n",
        "# If a table appears in the projects input, but is not present in the database or in the above list of tables:\n",
        "# it is assumed to be a daily table and added to the complete list of daily tables.\n",
        "# This means no tables mentioned in the projects input are missed.\n",
        "# >> Dictionary which contains lists of all tables in each of the Tables gantts\n",
        "fulllist_tables_dict = {\n",
        "    'monthly': monthly_tables_gantt.columns.tolist(),\n",
        "    'daily': daily_tables_gantt.columns.tolist()\n",
        "}\n",
        "for table in projects_csv_df.reset_index()['table'].unique():\n",
        "    if table not in set(fulllist_tables_dict['daily']).union(set(fulllist_tables_dict['monthly'])):\n",
        "        fulllist_tables_dict['daily'].append(table)\n",
        "\n",
        "# Function which takes Projects df, selects the appropriate timeframe (monthly or daily), \n",
        "# and creates a project_gantt for that timeframe\n",
        "def projects_gantt(timeframe ='monthly', freq='M'):\n",
        "    \n",
        "    # Create list of unique table names in appropriate timeframe (e.g. monthly or daily)\n",
        "    timeframe_tables_list = fulllist_tables_dict[timeframe]\n",
        "    \n",
        "    # Extracting tables which are only for the appropriate timeframe, then set index again\n",
        "    timeframe_projects = projects_csv_df.reset_index().loc[\n",
        "                                projects_csv_df.reset_index().table.isin(timeframe_tables_list)]\\\n",
        "                                .set_index(['project', 'table'])\n",
        "    \n",
        "    # Creating empty dataframe with index covering entire date range, and columns as unique table names \n",
        "    timeframe_projects_gantt = pd.DataFrame(\n",
        "                        index=pd.date_range(start=timeframe_projects.start.min(), \n",
        "                                            end=timeframe_projects.end.max(), freq=freq),\n",
        "                        columns=timeframe_tables_list)\n",
        "    \n",
        "    # For each row containing project, table, start date, end date\n",
        "    for row in timeframe_projects.iterrows():\n",
        "        start_dt = row[1][0]\n",
        "        end_dt = row[1][1]\n",
        "        project = row[0][0]\n",
        "        table = row[0][1]\n",
        "        # Create date range between start and end for project, then loop over\n",
        "        for date in pd.date_range(start=start_dt, end=end_dt, freq=freq):\n",
        "            # Want to fill in the project name into the cell\n",
        "            # If the cell already contains a project, want to add project name on top (not replace)\n",
        "            if pd.notnull(timeframe_projects_gantt.loc[date, table]):\n",
        "                timeframe_projects_gantt.loc[date, table] = timeframe_projects_gantt\\\n",
        "                                                                .loc[date, table]+'--'+project\n",
        "            else:\n",
        "                timeframe_projects_gantt.loc[date, table] = project\n",
        "                \n",
        "    return timeframe_projects_gantt\n",
        "\n",
        "# Calling function for Monthly & Daily\n",
        "# 'M' not 'MS' as otherwise adds an extra month on end (Jan 2019)\n",
        "monthly_projects_gantt = projects_gantt(timeframe ='monthly', freq='M')\n",
        "daily_projects_gantt = projects_gantt(timeframe ='daily', freq='D')\n",
        "\n",
        "# Displaying monthly dates as months not last days\n",
        "monthly_projects_gantt.index = monthly_projects_gantt.index.to_period('M')\n",
        "\n",
        "# Checking results\n",
        "monthly_projects_gantt.head(2)\n",
        "daily_projects_gantt.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DbxK0SJ5Vb8W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 5)a) DAILY: Combine the gantt chart from each input into an overall gantt\n",
        "# 6)a) This overall gantt includes all tables as columns, and all dates as the index.\n",
        "\n",
        "# Get union set of all daily dates, then use this to create daterange\n",
        "all_dates_daily = sorted(set(daily_projects_gantt.index).union(set(daily_tables_gantt.index)))\n",
        "full_daterange_daily = pd.date_range(start=min(all_dates_daily), end=max(all_dates_daily), freq='D')\n",
        "\n",
        "# Get union set of all daily columns\n",
        "all_columns_daily = sorted(set(daily_projects_gantt.columns).union(set(daily_tables_gantt.columns)))\n",
        "\n",
        "# Ensure both tables_gantt and projects_gantt have entire set of columns,\n",
        "# by adding any columns (with all values as NaNs) to each gantt if they aren't already present\n",
        "for col in all_columns_daily:\n",
        "    if col not in daily_projects_gantt.columns:\n",
        "        daily_projects_gantt[col] = np.nan\n",
        "    if col not in daily_tables_gantt.columns:\n",
        "        daily_tables_gantt[col] = np.nan\n",
        "\n",
        "# Order columns alphabetically for both gantts \n",
        "daily_projects_gantt = daily_projects_gantt[sorted(daily_projects_gantt.columns)]\n",
        "daily_tables_gantt = daily_tables_gantt[sorted(daily_tables_gantt.columns)]\n",
        "\n",
        "# Reindex both gantts to include full daterange. If date currently not there, fills NaN for all columns\n",
        "daily_projects_gantt = daily_projects_gantt.reindex(index=full_daterange_daily)\n",
        "daily_tables_gantt = daily_tables_gantt.reindex(index=full_daterange_daily)\n",
        "\n",
        "# Create frame of overall_gantt, with index as full daterange and columns as all columns\n",
        "daily_overall_gantt = pd.DataFrame(index=full_daterange_daily, columns=all_columns_daily)\n",
        "\n",
        "# For loop deploys actions for each column\n",
        "# 'Null' = if not in Tables, not needed in Projects\n",
        "# 'Drop' = if in Tables, not needed in Projects\n",
        "# 'Add' = if not in Tables, needed in Projects\n",
        "# 'Keep' = if in Tables, needed in Projects\n",
        "for col in daily_overall_gantt.columns:\n",
        "    # For loop over entire daterange\n",
        "    for date in daily_overall_gantt.index:\n",
        "        # Not in Tables\n",
        "        if pd.isnull(daily_tables_gantt.loc[date,col]):\n",
        "            # Whether in Projects\n",
        "            if pd.isnull(daily_projects_gantt.loc[date,col]):\n",
        "                daily_overall_gantt.loc[date,col] = 'Null'\n",
        "            elif pd.notnull(daily_projects_gantt.loc[date,col]):\n",
        "                daily_overall_gantt.loc[date,col] = 'Add: '+daily_projects_gantt.loc[date,col]\n",
        "            else:\n",
        "                daily_overall_gantt.loc[date,col] = 'Unsure1'\n",
        "        # Is in Tables\n",
        "        elif pd.notnull(daily_tables_gantt.loc[date,col]):\n",
        "            # Whether in Projects\n",
        "            if pd.isnull(daily_projects_gantt.loc[date,col]):\n",
        "                        daily_overall_gantt.loc[date,col] = 'Drop'\n",
        "            elif pd.notnull(daily_projects_gantt.loc[date,col]):\n",
        "                daily_overall_gantt.loc[date,col] = 'Keep: '+daily_projects_gantt.loc[date,col]\n",
        "            else:\n",
        "                daily_overall_gantt.loc[date,col] = 'Unsure2'\n",
        "        # If something has gone wrong..\n",
        "        else:\n",
        "            daily_overall_gantt.loc[date,col] = 'Unsure3'\n",
        "\n",
        "# Check results\n",
        "daily_overall_gantt.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pPzjQfVJgs64",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 5)a) MONTHLY: Combine the gantt chart from each input into an overall gantt\n",
        "# 6)a) This overall gantt includes all tables as columns, and all dates as the index.\n",
        "\n",
        "# Get union set of all monthly dates, then use this to create daterange\n",
        "# NB. more complicated because monthly dates stored as 'Periods', hence the extra syntax\n",
        "all_dates_monthly = sorted(\n",
        "                        set(monthly_projects_gantt.index)\\\n",
        "                        .union(set(monthly_tables_gantt.index))\n",
        "                        )\n",
        "full_daterange_monthly = pd.date_range(\n",
        "                            start=pd.to_datetime(str(min(all_dates_monthly))),\n",
        "                            end=pd.to_datetime(str(max(all_dates_monthly))), \n",
        "                            freq='MS')\\\n",
        "                            .to_period('M').tolist()\n",
        "\n",
        "# Get union set of all monthly columns\n",
        "all_columns_monthly = sorted(set(monthly_projects_gantt.columns).union(set(monthly_tables_gantt.columns)))\n",
        "\n",
        "# Ensure both tables_gantt and projects_gantt have entire set of columns,\n",
        "# by adding any columns (with all values as NaNs) to each gantt if they aren't already present\n",
        "for col in all_columns_monthly:\n",
        "    if col not in monthly_projects_gantt.columns:\n",
        "        monthly_projects_gantt[col] = np.nan\n",
        "    if col not in monthly_tables_gantt.columns:\n",
        "        monthly_tables_gantt[col] = np.nan\n",
        "\n",
        "# Order columns alphabetically for both gantts \n",
        "monthly_projects_gantt = monthly_projects_gantt[sorted(monthly_projects_gantt.columns)]\n",
        "monthly_tables_gantt = monthly_tables_gantt[sorted(monthly_tables_gantt.columns)]\n",
        "\n",
        "# Reindex both gantts to include full daterange. If date currently not there, fills NaN for all columns\n",
        "# NB. more complicated because monthly dates stored as 'Periods', hence the extra syntax\n",
        "monthly_projects_gantt.index = monthly_projects_gantt.index.tolist()\n",
        "monthly_tables_gantt.index = monthly_tables_gantt.index.tolist()\n",
        "\n",
        "monthly_projects_gantt = monthly_projects_gantt.reindex(index=full_daterange_monthly)\n",
        "monthly_tables_gantt = monthly_tables_gantt.reindex(index=full_daterange_monthly)\n",
        "\n",
        "# Create frame of overall_gantt, with index as full daterange and columns as all columns\n",
        "monthly_overall_gantt = pd.DataFrame(index=full_daterange_monthly, columns=all_columns_monthly)\n",
        "\n",
        "# For loop deploys actions for each column\n",
        "# 'Null' = if not in Tables, not needed in Projects\n",
        "# 'Drop' = if in Tables, not needed in Projects\n",
        "# 'Add' = if not in Tables, needed in Projects\n",
        "# 'Keep' = if in Tables, needed in Projects\n",
        "for col in monthly_overall_gantt.columns:\n",
        "    # For loop over entire daterange \n",
        "    for date in monthly_overall_gantt.index:\n",
        "        # Not in Tables\n",
        "        if pd.isnull(monthly_tables_gantt.loc[date,col]):\n",
        "            # Whether in Projects\n",
        "            if pd.isnull(monthly_projects_gantt.loc[date,col]):\n",
        "                monthly_overall_gantt.loc[date,col] = 'Null'\n",
        "            elif pd.notnull(monthly_projects_gantt.loc[date,col]):\n",
        "                monthly_overall_gantt.loc[date,col] = 'Add: '+monthly_projects_gantt.loc[date,col]\n",
        "            else:\n",
        "                monthly_overall_gantt.loc[date,col] = 'Unsure1'\n",
        "        # Is in Tables\n",
        "        elif pd.notnull(monthly_tables_gantt.loc[date,col]):\n",
        "            # Whether in Projects\n",
        "            if pd.isnull(monthly_projects_gantt.loc[date,col]):\n",
        "                monthly_overall_gantt.loc[date,col] = 'Drop'\n",
        "            elif pd.notnull(monthly_projects_gantt.loc[date,col]):\n",
        "                monthly_overall_gantt.loc[date,col] = 'Keep: '+monthly_projects_gantt.loc[date,col]\n",
        "            else:\n",
        "                monthly_overall_gantt.loc[date,col] = 'Unsure2'\n",
        "        # If something has gone wrong..\n",
        "        else:\n",
        "            monthly_overall_gantt.loc[date,col] = 'Unsure3'\n",
        "\n",
        "# Check results\n",
        "monthly_overall_gantt.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FNHhEh72gs67",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 7) Adjust output of overall gantts to take into account Jira tickets, for both timeframes\n",
        "\n",
        "# Read in Projects data\n",
        "old_monthly_gantt = pd.read_excel(spreadsheet_link, \n",
        "                                sheet_name='***', \n",
        "                                header=2, index_col=0)\n",
        "old_daily_gantt = pd.read_excel(spreadsheet_link, \n",
        "                                sheet_name='***', \n",
        "                                header=2, index_col=0)\n",
        "old_monthly_gantt.head(2)\n",
        "old_daily_gantt.head(2)\n",
        "\n",
        "# Make sure old gantt chart contains only columns from new overall gantt\n",
        "old_monthly_gantt = old_monthly_gantt[monthly_overall_gantt.columns]\n",
        "old_daily_gantt = old_daily_gantt[daily_overall_gantt.columns]\n",
        "\n",
        "# If 'jira' in old gantt, fill that cell in the new gantt with the jira link\n",
        "for col in old_monthly_gantt.columns:\n",
        "    for date in old_monthly_gantt.index:\n",
        "        if 'jira.' in old_monthly_gantt.loc[date,col]:\n",
        "            if 'Add:' in monthly_overall_gantt.loc[date,col]:\n",
        "                monthly_overall_gantt.loc[date,col] = old_monthly_gantt.loc[date,col]\n",
        "for col in old_daily_gantt.columns:\n",
        "    for date in old_daily_gantt.index:\n",
        "        if 'jira.' in old_daily_gantt.loc[date,col]:\n",
        "            if 'Add:' in daily_overall_gantt.loc[date,col]:\n",
        "                daily_overall_gantt.loc[date,col] = old_daily_gantt.loc[date,col]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xy4Lyme8gs7B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 8) Dataframe of how much space is taken up by the tables associated with each project\n",
        "\n",
        "# Creates skeleton df\n",
        "projects_sizes = pd.DataFrame(\n",
        "    index=sorted(projects_csv_df.reset_index().project.unique()), \n",
        "    columns=['size_MBs'], \n",
        "    data=0)\n",
        "\n",
        "# MONTHLY: Add the relevant datatable sizes to the projects_sizes df\n",
        "# For all dates and tablenames in tables_gantt\n",
        "for date in monthly_tables_gantt.index:\n",
        "    for column in monthly_tables_gantt.columns:\n",
        "        # Only if it's a 'Keep' will the data be in the database AND it is needed by a project\n",
        "        if 'Keep:' in monthly_overall_gantt.loc[date,column]:\n",
        "            # This covers date-tablename combinations which are required for multiple projects.\n",
        "            # Add the size to each project\n",
        "            split_projects = monthly_projects_gantt.loc[date,column].split('--')\n",
        "            for project in split_projects:\n",
        "                # Add datatable size to the appropriate project in the projects_sizes df \n",
        "                projects_sizes.loc[project, 'size_MBs'] += monthly_tables_gantt.loc[date,column]\n",
        "\n",
        "# MONTHLY: Add the relevant datatable sizes to the projects_sizes df\n",
        "# For all dates and tablenames in tables_gantt\n",
        "for date in daily_tables_gantt.index:\n",
        "    for column in daily_tables_gantt.columns:\n",
        "        # Only if it's a 'Keep' will the data be in the database AND it is needed by a project\n",
        "        if 'Keep:' in daily_overall_gantt.loc[date,column]:\n",
        "            # This covers date-tablename combinations which are required for multiple projects.\n",
        "            # Add the size to each project\n",
        "            split_projects = daily_projects_gantt.loc[date,column].split('--')\n",
        "            for project in split_projects:\n",
        "                # Add datatable size to the appropriate project in the projects_sizes df \n",
        "                projects_sizes.loc[project, 'size_MBs'] += round(daily_tables_gantt.loc[date,column])\n",
        "\n",
        "# Check I'm not being dumb\n",
        "projects_sizes.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qaqn4pg720x9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 9) Creates dataframe, from Tables input, of how much space each schema takes up in the database\n",
        "\n",
        "# Check imported tables df\n",
        "all_tables_df.head(2)\n",
        "\n",
        "# Create copy of base tables df\n",
        "other_tables_df = all_tables_df.copy()\n",
        "\n",
        "# Extract Size measurement & unit\n",
        "other_tables_df['size_num'] = other_tables_df['size'].apply(\n",
        "    lambda x: int(x.split(' ')[0]) if x is not None\n",
        "    else np.nan)\n",
        "other_tables_df['size_unit'] = other_tables_df.size.apply(\n",
        "    lambda x: x.split(' ')[-1] if x is not None\n",
        "    else np.nan)\n",
        "\n",
        "# Used pre-defined function (near top of script) to create standardised size in MBs\n",
        "other_tables_df['size_MBs'] = other_tables_df.apply(lambda row: into_MBs(row), axis=1)\n",
        "\n",
        "# Groupby Schema name, summing sizes in MB\n",
        "table_size_df = pd.DataFrame(other_tables_df.groupby('***').size_MBs.sum()).reset_index()\n",
        "\n",
        "# playpen tables are stored under 'playpen'('***'), whereas the rest are stored under main ('***')\n",
        "table_size_df['partition'] = table_size_df.apply(lambda row: 'playpen' if row['***'][:7] == '***' \\\n",
        "                                                          else 'main', axis=1)\n",
        "size_main = '***'\n",
        "size_playpen = '***'\n",
        "\n",
        "# Create column to display percentage of storage taken up by this schema\n",
        "table_size_df['perc_storage'] = table_size_df.apply(\n",
        "                                    lambda row: row['size_MBs']/(size_main) if row['partition'] == 'main' \\\n",
        "                                    else row['size_MBs']/(size_playpen), axis=1)\n",
        "\n",
        "# Check output\n",
        "table_size_df.head(2)\n",
        "\n",
        "# Create vars which sum the size of tables for each partition\n",
        "used_size_playpen = table_size_df[table_size_df.partition == 'playpen'].size_MBs.sum()\n",
        "used_size_main = table_size_df[table_size_df.partition == 'main'].size_MBs.sum()\n",
        "\n",
        "# Created another df of 'unused' space\n",
        "unused_df = pd.DataFrame(\n",
        "    data={\n",
        "        '***':['unused']*2,\n",
        "        'size_MBs':[size_main-used_size_main, size_playpen-used_size_playpen],\n",
        "        'partition':['main', 'playpen'],\n",
        "        'perc_storage':[(size_main - used_size_main) / size_main, \n",
        "                        (size_playpen - used_size_playpen) / size_playpen]\n",
        "    } ,\n",
        "    columns=table_size_df.columns)\n",
        "\n",
        "# Append the two tablesize dfs into one final output\n",
        "final_tablesize_df = unused_df.append(table_size_df, ignore_index=True)\n",
        "final_tablesize_df.head(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EC-Ok4acdF_p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 10) Export into the spreadsheet: the two overall gantts, the project sizes dataframe, and the schema sizes dataframe\n",
        "\n",
        "# To write to excel\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "# In order not to overwrite columns\n",
        "book = load_workbook(spreadsheet_link)\n",
        "writer = pd.ExcelWriter(spreadsheet_link, engine='openpyxl')\n",
        "writer.book = book\n",
        "writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
        "\n",
        "monthly_overall_gantt.to_excel(writer, sheet_name='OUTPUT_monthly_overall_gantt', index=True)\n",
        "daily_overall_gantt.to_excel(writer, sheet_name='OUTPUT_daily_overall_gantt', index=True)\n",
        "projects_sizes.to_excel(writer, sheet_name='OUTPUT_project_sizes', index=True)\n",
        "final_tablesize_df.to_excel(writer, sheet_name='OUTPUT_schema_sizes', index=False)\n",
        "\n",
        "# Saves final spreadsheet\n",
        "writer.save()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}